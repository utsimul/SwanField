{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3M6rURpybvn"
      },
      "source": [
        "# SF - TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymZ1h6Ggy3CZ",
        "outputId": "ff80d764-c8ef-4bf3-9d34-f4119a0cea0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting arch\n",
            "  Downloading arch-8.0.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
            "Collecting ta\n",
            "  Downloading ta-0.11.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Collecting hmmlearn\n",
            "  Downloading hmmlearn-0.3.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.12/dist-packages (0.2.66)\n",
            "Requirement already satisfied: statsmodels>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from arch) (0.14.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from arch) (25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: scikit-learn!=0.22.0,>=0.16 in /usr/local/lib/python3.12/dist-packages (from hmmlearn) (1.6.1)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.32.4)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.0.12)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.5.0)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.12/dist-packages (from yfinance) (3.18.3)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.13.5)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.13.0)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (5.29.5)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (15.0.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.8)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (2.0.0)\n",
            "Requirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (2025.10.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (2.5.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (3.6.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.13.0->arch) (1.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.23)\n",
            "Downloading arch-8.0.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (981 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.3/981.3 kB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hmmlearn-0.3.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: ta\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta: filename=ta-0.11.0-py3-none-any.whl size=29412 sha256=3055021fd55896566f6f12b2476627a97ea0eeffa336c928516ea6fe5262aac5\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/a1/5f/c6b85a7d9452057be4ce68a8e45d77ba34234a6d46581777c6\n",
            "Successfully built ta\n",
            "Installing collected packages: ta, hmmlearn, arch\n",
            "Successfully installed arch-8.0.0 hmmlearn-0.3.3 ta-0.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install arch ta pandas numpy torch hmmlearn scipy yfinance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CcQfeydzwGi"
      },
      "source": [
        "## preprocessing.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "odytLhcEyVIZ"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from arch import arch_model\n",
        "from ta.trend import SMAIndicator, EMAIndicator\n",
        "from ta.volatility import BollingerBands\n",
        "from ta.momentum import RSIIndicator\n",
        "\n",
        "# Color codes for logging\n",
        "RED = '\\033[91m'\n",
        "GREEN = '\\033[92m'\n",
        "YELLOW = '\\033[93m'\n",
        "BLUE = '\\033[94m'\n",
        "ENDC = '\\033[0m'\n",
        "\n",
        "def fetch_data(tickers=['AAPL', 'GOOGL'], start=\"2007-01-01\", end=\"2024-12-31\"):\n",
        "    \"\"\"Fetch OHLCV data from yfinance, preserving DatetimeIndex.\"\"\"\n",
        "    data = yf.download(tickers, start=start, end=end, auto_adjust=True)\n",
        "    ticker_dfs = {}\n",
        "    for ticker in tickers:\n",
        "        ticker_data = data.xs(ticker, axis=1, level=1) if len(tickers) > 1 else data\n",
        "        ticker_data.columns = [col.lower() for col in ticker_data.columns]\n",
        "        ticker_data.index = pd.to_datetime(ticker_data.index)\n",
        "        ticker_dfs[ticker] = ticker_data\n",
        "    print(GREEN + f\"Fetched data for {tickers}\" + ENDC)\n",
        "    return ticker_dfs\n",
        "\n",
        "def clean_data(df, ticker):\n",
        "    \"\"\"Clean data, preserving DatetimeIndex and minimizing row loss.\"\"\"\n",
        "    print(BLUE + f\"Step 1: Cleaning data for {ticker}\" + ENDC)\n",
        "    if df is None or df.empty:\n",
        "        print(RED + f\"No data for {ticker}\" + ENDC)\n",
        "        return None\n",
        "\n",
        "    print(f\"Initial shape: {df.shape}, index type: {type(df.index)}\")\n",
        "    print(f\"Date range: {df.index.min()} to {df.index.max()}\")\n",
        "    print(f\"NaN counts:\\n{df.isna().sum()}\")\n",
        "\n",
        "    df = df.copy()\n",
        "    df = df.dropna(subset=['open', 'high', 'low', 'close', 'volume'])\n",
        "    print(f\"After dropna OHLCV shape: {df.shape}\")\n",
        "\n",
        "    df['return'] = df['close'].pct_change().fillna(0)\n",
        "    df['volatility'] = df['return'].rolling(window=21).std() * np.sqrt(252)\n",
        "    df['momentum'] = df['return'].rolling(window=21).mean()\n",
        "\n",
        "    mean_ret, std_ret = df['return'].mean(), df['return'].std()\n",
        "    df = df[abs(df['return'] - mean_ret) <= 5 * std_ret]\n",
        "    print(f\"After outlier removal shape: {df.shape}\")\n",
        "\n",
        "    df = df.drop_duplicates()\n",
        "    print(f\"After drop duplicates shape: {df.shape}\")\n",
        "\n",
        "    print(BLUE + f\"Cleaned data shape: {df.shape}\" + ENDC)\n",
        "    print(f\"NaN counts after cleaning:\\n{df.isna().sum()}\")\n",
        "    return df\n",
        "\n",
        "def compute_features(df):\n",
        "    \"\"\"Compute technical indicators and features.\"\"\"\n",
        "    if df is None or df.empty:\n",
        "        return None\n",
        "\n",
        "    df_features = df.copy()\n",
        "    close_series = df_features['close']\n",
        "\n",
        "    df_features['SMA_10'] = SMAIndicator(close_series, window=10).sma_indicator()\n",
        "    df_features['EMA_10'] = EMAIndicator(close_series, window=10).ema_indicator()\n",
        "    df_features['RSI_14'] = RSIIndicator(close_series, window=14).rsi()\n",
        "    bb = BollingerBands(close_series, window=10, window_dev=2)\n",
        "    df_features['BB_High'] = bb.bollinger_hband()\n",
        "    df_features['BB_Low'] = bb.bollinger_lband()\n",
        "    df_features['Log_Returns'] = np.log(close_series / close_series.shift(1))\n",
        "    df_features['Volatility_10'] = df_features['Log_Returns'].rolling(window=10).std() * np.sqrt(252)\n",
        "\n",
        "    def hurst_exponent(series, lag=20, min_std=1e-6):\n",
        "        if len(series) < lag:\n",
        "            return np.nan\n",
        "        series = series.dropna()\n",
        "        if len(series) < 10:\n",
        "            return np.nan\n",
        "        lags = range(2, min(lag, len(series)))\n",
        "        rs = []\n",
        "        for lag in lags:\n",
        "            lagged_diff = series.diff(lag).dropna()\n",
        "            if len(lagged_diff) < 5:\n",
        "                continue\n",
        "            rs_range = lagged_diff.max() - lagged_diff.min()\n",
        "            rs_std = max(lagged_diff.std(), min_std)\n",
        "            rs.append(np.log(rs_range / rs_std) / np.log(lag) if rs_range > 0 else np.nan)\n",
        "        return np.nanmean(rs) if rs else np.nan\n",
        "\n",
        "    df_features['Hurst'] = df_features['Log_Returns'].rolling(window=30).apply(hurst_exponent, raw=False)\n",
        "\n",
        "    print(BLUE + f\"Features computed shape (before dropna): {df_features.shape}\" + ENDC)\n",
        "    print(f\"NaN counts before dropna:\\n{df_features.isna().sum()}\")\n",
        "\n",
        "    critical_columns = ['Log_Returns', 'Volatility_10', 'RSI_14', 'momentum', 'volume']\n",
        "    df_features = df_features.loc[df_features[critical_columns].notna().all(axis=1)]\n",
        "    print(f\"Features computed shape (after dropna critical): {df_features.shape}\")\n",
        "\n",
        "    for col in ['SMA_10', 'EMA_10', 'BB_High', 'BB_Low', 'Hurst', 'volatility']:\n",
        "        if col in df_features.columns:\n",
        "            df_features[col] = df_features[col].interpolate().ffill().bfill()\n",
        "\n",
        "    print(f\"NaN counts after imputation:\\n{df_features.isna().sum()}\")\n",
        "    return df_features\n",
        "\n",
        "def normalize_data(df, columns=['open', 'high', 'low', 'close', 'volume', 'SMA_10', 'EMA_10', 'RSI_14', 'BB_High', 'BB_Low', 'Volatility_10']):\n",
        "    \"\"\"Normalize specified columns.\"\"\"\n",
        "    if df is None or df.empty:\n",
        "        return None, None\n",
        "\n",
        "    df_normalized = df.copy()\n",
        "    scalers = {}\n",
        "\n",
        "    for col in columns:\n",
        "        if col in df_normalized.columns:\n",
        "            scaler = MinMaxScaler()\n",
        "            scaled_values = scaler.fit_transform(df_normalized[[col]].values.reshape(-1, 1)).flatten()\n",
        "            df_normalized[col] = scaled_values\n",
        "            scalers[col] = scaler\n",
        "        else:\n",
        "            print(YELLOW + f\"Warning: Column {col} not found in DataFrame\" + ENDC)\n",
        "\n",
        "    print(BLUE + f\"Normalized data shape: {df_normalized.shape}\" + ENDC)\n",
        "    return df_normalized, scalers\n",
        "\n",
        "def fit_garch_model(returns, p=1, q=1, window=200):\n",
        "    \"\"\"Fit a rolling GARCH model.\"\"\"\n",
        "    try:\n",
        "        returns = returns.dropna()\n",
        "        if len(returns) < 50:\n",
        "            print(RED + \"Insufficient data for GARCH model\" + ENDC)\n",
        "            return pd.Series(np.nan, index=returns.index)\n",
        "\n",
        "        scale_factor = 100\n",
        "        scaled_returns = returns * scale_factor\n",
        "        volatility = []\n",
        "        failures = 0\n",
        "        for i in range(len(returns)):\n",
        "            if i < window:\n",
        "                volatility.append(np.nan)\n",
        "                continue\n",
        "            window_returns = scaled_returns.iloc[max(0, i-window):i]\n",
        "            if len(window_returns) < 50:\n",
        "                volatility.append(np.nan)\n",
        "                continue\n",
        "            try:\n",
        "                model = arch_model(window_returns, vol='Garch', p=p, q=q, dist='Normal', mean='Zero', rescale=False)\n",
        "                garch_fit = model.fit(disp='off', options={'maxiter': 1000})\n",
        "                forecast = garch_fit.forecast(horizon=1)\n",
        "                volatility.append(np.sqrt(forecast.variance.values[-1, :])[0] / scale_factor)\n",
        "            except Exception as e:\n",
        "                failures += 1\n",
        "                volatility.append(np.nan)\n",
        "        volatility_series = pd.Series(volatility, index=returns.index)\n",
        "        print(f\"GARCH volatility forecast (last): {volatility_series.iloc[-1]:.4f}\")\n",
        "        print(f\"GARCH NaN count: {volatility_series.isna().sum()}\")\n",
        "        print(f\"GARCH failures: {failures}\")\n",
        "        return volatility_series\n",
        "    except Exception as e:\n",
        "        print(RED + f\"GARCH model fitting failed entirely: {e}\" + ENDC)\n",
        "        return pd.Series(np.nan, index=returns.index)\n",
        "\n",
        "def process_asset_data(data_dict, ticker, augment=False):\n",
        "    \"\"\"Process data for a single ticker.\"\"\"\n",
        "    df = data_dict.get(ticker)\n",
        "    if df is None or len(df) < 100:\n",
        "        print(RED + f\"Insufficient data for {ticker}\" + ENDC)\n",
        "        return None, None\n",
        "\n",
        "    print(GREEN + f\"Processing ticker: {ticker}\" + ENDC)\n",
        "    print(f\"Initial data shape: {df.shape}, date range: {df.index.min()} to {df.index.max()}\")\n",
        "    for s, e in [('2008-09-01', '2009-03-15'), ('2020-02-15', '2020-03-31')]:\n",
        "        mask = (df.index >= pd.to_datetime(s)) & (df.index <= pd.to_datetime(e))\n",
        "        print(f\"{s} to {e}: {mask.sum()} rows\")\n",
        "\n",
        "    df_cleaned = clean_data(df, ticker)\n",
        "    if df_cleaned is None:\n",
        "        return None, None\n",
        "\n",
        "    df_features = compute_features(df_cleaned)\n",
        "    if df_features is None:\n",
        "        return None, None\n",
        "\n",
        "    returns = df_features['Log_Returns'].dropna()\n",
        "    garch_vol = fit_garch_model(returns)\n",
        "    df_features['GARCH_Vol'] = garch_vol\n",
        "    if df_features['GARCH_Vol'].isna().all():\n",
        "        print(YELLOW + f\"GARCH failed for {ticker}; using rolling std as fallback\" + ENDC)\n",
        "        df_features['GARCH_Vol'] = df_features['Log_Returns'].rolling(window=21).std() * np.sqrt(252)\n",
        "    df_features['GARCH_Vol'] = df_features['GARCH_Vol'].interpolate().ffill().bfill()\n",
        "    print(BLUE + \"trying on fixes\" + ENDC)\n",
        "    df_features['GARCH_Vol'] = np.sqrt(df_features['GARCH_Vol']) #this works\n",
        "    #df['GARCH_Vol'] = df['GARCH_Vol'] / np.sqrt(252)\n",
        "\n",
        "    df_normalized, scalers = normalize_data(df_features)\n",
        "    if df_normalized is None:\n",
        "        return None, None\n",
        "\n",
        "    autoencoder_columns = ['open', 'high', 'low', 'close', 'volume', 'SMA_10', 'EMA_10', 'RSI_14', 'BB_High', 'BB_Low', 'Volatility_10']\n",
        "    for col in autoencoder_columns:\n",
        "        if col in df_normalized.columns:\n",
        "            min_val, max_val = df_normalized[col].min(), df_normalized[col].max()\n",
        "            if not (0 <= min_val <= max_val <= 1):\n",
        "                print(YELLOW + f\"Warning: Column {col} not scaled properly (min={min_val:.4f}, max={max_val:.4f})\" + ENDC)\n",
        "\n",
        "    for s, e in [('2008-09-01', '2009-03-15'), ('2020-02-15', '2020-03-31')]:\n",
        "        mask = (df_normalized.index >= pd.to_datetime(s)) & (df_normalized.index <= pd.to_datetime(e))\n",
        "        print(f\"{s} to {e} after processing: {mask.sum()} rows\")\n",
        "        print(f\"Feature ranges in {s} to {e}:\")\n",
        "        for col in ['Log_Returns', 'Volatility_10', 'GARCH_Vol', 'momentum', 'RSI_14', 'volume', 'Hurst']:\n",
        "            if col in df_normalized.columns:\n",
        "                min_val = df_normalized[mask][col].min()\n",
        "                max_val = df_normalized[mask][col].max()\n",
        "                mean_val = df_normalized[mask][col].mean()\n",
        "                print(f\"  {col}: min={min_val:.4f}, max={max_val:.4f}, mean={mean_val:.4f}\")\n",
        "\n",
        "    print(GREEN + f\"Final processed data for {ticker} shape: {df_normalized.shape}\" + ENDC)\n",
        "    return df_normalized, scalers\n",
        "\n",
        "def process_multiple_assets(data_dict, tickers, augment=False):\n",
        "    \"\"\"Process multiple tickers.\"\"\"\n",
        "    results = {}\n",
        "    for ticker in tickers:\n",
        "        df_processed, scalers = process_asset_data(data_dict, ticker, augment=augment)\n",
        "        results[ticker] = {'data': df_processed, 'scalers': scalers}\n",
        "        print(GREEN + f\"Processed data for ticker {ticker}\" + ENDC)\n",
        "    return results\n",
        "\n",
        "def run(tickers, start_date, end_date, augment, otpt_show, save=True, outdir=\"output_data\"):\n",
        "    import os\n",
        "\n",
        "    if save:\n",
        "        os.makedirs(outdir, exist_ok=True)\n",
        "\n",
        "    data_dict = fetch_data(tickers, start_date, end_date)\n",
        "    results = process_multiple_assets(data_dict, tickers, augment=augment)\n",
        "\n",
        "    if otpt_show:\n",
        "        for ticker, result in results.items():\n",
        "            df_processed = result['data']\n",
        "            if df_processed is not None:\n",
        "                print(f\"Processed data shape for {ticker}: {df_processed.shape}\")\n",
        "                print(f\"Date range: {df_processed.index.min()} to {df_processed.index.max()}\")\n",
        "                print(f\"GARCH Volatility (last): {df_processed['GARCH_Vol'].iloc[-1]:.4f}\")\n",
        "\n",
        "    if save:\n",
        "        for ticker, result in results.items():\n",
        "            df_processed = result['data']\n",
        "            if df_processed is not None:\n",
        "                filename = os.path.join(outdir, f\"{ticker}_processed.csv\")\n",
        "                df_processed.to_csv(filename, index=True)\n",
        "                print(GREEN + f\"Saved processed data for {ticker} to {filename}\" + ENDC)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SMqKuIfzswz"
      },
      "source": [
        "## helpernets.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cUkzUVtZzmAa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class attention_pool(nn.Module):\n",
        "    def __init__(self, embed_dim: int):\n",
        "        super().__init__()\n",
        "        self.Q = nn.Parameter(torch.randn(embed_dim))   # [d]\n",
        "        self.K = nn.Linear(embed_dim, embed_dim)\n",
        "        self.V = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "    def forward(self, h_inputs: torch.Tensor):\n",
        "        \"\"\"\n",
        "        h_inputs: [batch, N, d]\n",
        "        Returns:\n",
        "            h_out: [batch, d]\n",
        "            alphas: [batch, N]\n",
        "        \"\"\"\n",
        "        keys = self.K(h_inputs)      # [batch, N, d]\n",
        "        values = self.V(h_inputs)    # [batch, N, d]\n",
        "\n",
        "        # Compute attention scores\n",
        "        # Q: [d] → broadcast to [batch, d]\n",
        "        eij = torch.matmul(keys, self.Q)      # [batch, N, d] · [d] -> [batch, N]\n",
        "\n",
        "        alphas = torch.softmax(eij, dim=1)    # softmax over assets per batch\n",
        "\n",
        "        h_out = torch.sum(values * alphas.unsqueeze(-1), dim=1)  # [batch, d]\n",
        "        print(GREEN + \"h_out from attention pool is: \", h_out)\n",
        "\n",
        "        return h_out, alphas\n",
        "\n",
        "def ensure_tensor(x, device, dtype=torch.float32):\n",
        "    if torch.is_tensor(x):\n",
        "        return x.to(device, dtype=dtype)\n",
        "    else:\n",
        "        return torch.tensor(x, dtype=dtype, device=device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHYi71w6z9TC"
      },
      "source": [
        "## asset agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "jbY0yrY2zzax"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Categorical, Normal\n",
        "#from helpernets import ensure_tensor\n",
        "\n",
        "#Dont forget:\n",
        "# - CONCAT MEMORY ONTO NON SEQ DATA either in train.py or here\n",
        "\n",
        "\n",
        "class Asset_Seq_Encoder(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            seq_input_dim : int,\n",
        "            recurrent_layers : int = 1,\n",
        "            network : str = \"lstm\",\n",
        "            recurrent_neurons : int = 64,\n",
        "\n",
        "    ):\n",
        "        super().__init__()\n",
        "        #Experiment with LSTM, 1D CNN, GRU\n",
        "        if(network == \"lstm\"):\n",
        "            self.network = nn.LSTM(seq_input_dim, recurrent_neurons, recurrent_layers, batch_first = True)\n",
        "        elif(network == \"gru\"):\n",
        "            self.network = nn.GRU(seq_input_dim, recurrent_neurons, recurrent_layers, batch_first = True)\n",
        "        else:\n",
        "            print(\"Encoder choice for sequence data doesn't match.\")\n",
        "\n",
        "    def forward(self, seq_data : torch.Tensor):\n",
        "\n",
        "        _, (h_n, _) = self.network(seq_data) #h_n = (L,B,N_r) or (no of recc layers, batch size, no of recc neurons)\n",
        "        return h_n[-1] #[-1] means we are taking the hidden state value of the last recurrent neuron. (L,B) #by default this is (1,B)\n",
        "\n",
        "\n",
        "class AssetPolicyNet(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            seq_input_dim: int,\n",
        "            non_seq_input_dim : int,\n",
        "            hidden_dim_seq : int=64,\n",
        "            hidden_dim : int = 128,\n",
        "            num_discrete: int = 3, #BUY, SELL, HOLD\n",
        "            memory_dim : int=1, #dimensions of memory update output\n",
        "            num_signal : int = 2, #signal from asset to domain\n",
        "            min_std : float = 1e-3, #Minimum standard deviation for the Normal distribution of the memory update.\n",
        "            ):\n",
        "        super().__init__()\n",
        "        self.encoder = Asset_Seq_Encoder(seq_input_dim, hidden_dim_seq) #returns (L,B)\n",
        "        self.shared_net = nn.Linear(hidden_dim_seq + non_seq_input_dim, hidden_dim)\n",
        "        self.actor_bhs = nn.Linear(hidden_dim, num_discrete) #actor head 1: BUY HOLD SELL\n",
        "\n",
        "        #fraction of trades made\n",
        "        self.trade_frac_mean = nn.Linear(hidden_dim, 1)\n",
        "        self.trade_frac_std = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "        self.asset_to_domain_mean = nn.Linear(hidden_dim, num_signal) #actor head 2: signal to domain agent\n",
        "        self.asset_to_domain_std = nn.Linear(hidden_dim, num_signal)\n",
        "        #if num_signals are 2, means we want the policy to determine 2 values. This means we create 2 gaussian\n",
        "        #distributions - one for each of the output variables (therefore 2 means and 2 std devs), and pick one value\n",
        "        #from each distribution\n",
        "\n",
        "        self.mem_update_mean = nn.Linear(hidden_dim, memory_dim) #actor head 3: memory update value\n",
        "        self.mem_update_std = nn.Linear(hidden_dim, memory_dim)\n",
        "\n",
        "        self.critic = nn.Linear(hidden_dim, 1) #critic outputs the estimated value\n",
        "        self.min_std = min_std\n",
        "\n",
        "\n",
        "    def forward(self, seq_data, non_seq_data):\n",
        "\n",
        "        #seq_data is [B,T,F] and non_seq_data is [B, 2 values (alloc and mem)]\n",
        "\n",
        "        seq_encoding = self.encoder(seq_data) #returns as (L,B)\n",
        "        #seq_encoding = seq_encoding.transpose(0,1) #convert that (L,B) to (B,L)\n",
        "        net_x = torch.cat([seq_encoding, non_seq_data], dim=1) #join along the dimension L or encoding cols. so batch is same and cols\n",
        "        #of encoding and B put beside each other. => net becomes (B, L+2)\n",
        "        net_enc_hidden = torch.tanh(self.shared_net(net_x)) #hidden_dim neurons (by default 128)\n",
        "\n",
        "        #BUY HOLD SELL (categorical policy):\n",
        "        logits = self.actor_bhs(net_enc_hidden) #(B,3) 3 for B,H,S\n",
        "        bhs = Categorical(logits = logits)\n",
        "\n",
        "        #ASSET TO DOMAIN SIGNAL\n",
        "        ast_to_dom_mean = self.asset_to_domain_mean(net_enc_hidden) #gives 2 (num_signal) => (B,2)\n",
        "        ast_do_dom_logstd = self.asset_to_domain_std(net_enc_hidden).clamp(min=torch.log(torch.tensor(self.min_std))) #gives 2 logstds\n",
        "        ast_to_dom_std = ast_do_dom_logstd.exp() #calculate logstd to ensure that values are positive\n",
        "        ast_to_dom = Normal(ast_to_dom_mean, ast_to_dom_std) #outputs a Gaussian distribution\n",
        "        #every time the actor processes data, it calculates a new policy - a new distribution and then we sample the action\n",
        "        #from that distribution, encouraging exploration and exploitation based on a distribution rather than strict epsilon\n",
        "        #greedy percentages\n",
        "\n",
        "        #MEMORY UPDATE SIGNAL\n",
        "        mem_mean = self.mem_update_mean(net_enc_hidden) #gives 2 means => (B,2)\n",
        "        mem_logstd = self.mem_update_std(net_enc_hidden).clamp(min=torch.log(torch.tensor(self.min_std))) #gives 2 log std\n",
        "        mem_std = mem_logstd.exp() #calculate logstd to ensure that values are positive\n",
        "        mem_update = Normal(mem_mean, mem_std)\n",
        "\n",
        "        # TRADE FRACTION HEAD (continuous between 0 and 1)\n",
        "        frac_mean = torch.sigmoid(self.trade_frac_mean(net_enc_hidden))  # ensures [0,1]\n",
        "        frac_logstd = self.trade_frac_std(net_enc_hidden).clamp(min=torch.log(torch.tensor(self.min_std)))\n",
        "        frac_std = frac_logstd.exp()\n",
        "        trade_frac = Normal(frac_mean, frac_std)\n",
        "\n",
        "\n",
        "        value = self.critic(net_enc_hidden).squeeze(-1)\n",
        "\n",
        "        return bhs, ast_to_dom, mem_update, trade_frac, value\n",
        "\n",
        "\n",
        "class AssetAgent(nn.Module):\n",
        "\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            seq_input_dim,\n",
        "            non_seq_input_dim,\n",
        "            hidden_dim_seq = 64,\n",
        "            hidden_dim = 128,\n",
        "            num_discrete = 3,\n",
        "            memory_dim = 1,\n",
        "            num_signal = 2, #signal sent from asset to domain\n",
        "            min_std = 1e-3,\n",
        "            lr = 3e-4,\n",
        "            clip_eps = 0.2,\n",
        "            c1 = 0.5, #value coefficient (multiplied with L^{value})\n",
        "            c2 = 0.01, #entropy coefficient (multiplied with entropy of action distributions)\n",
        "            device = \"cpu\"\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.policynet = AssetPolicyNet(\n",
        "            seq_input_dim=seq_input_dim,\n",
        "            non_seq_input_dim=non_seq_input_dim,\n",
        "            hidden_dim_seq=hidden_dim_seq,\n",
        "            hidden_dim=hidden_dim,\n",
        "            num_discrete=num_discrete,\n",
        "            memory_dim=memory_dim,\n",
        "            num_signal=num_signal,\n",
        "            min_std=min_std\n",
        "        ).to(device)\n",
        "\n",
        "        self.optimizer = optim.Adam(self.policynet.parameters(), lr=lr)\n",
        "\n",
        "        self.clip_eps = clip_eps\n",
        "        self.c1 = c1\n",
        "        self.c2 = c2\n",
        "\n",
        "    def act(self, seq_data, non_seq_data):\n",
        "\n",
        "        #CONCAT MEMORY ONTO NON SEQ DATA - EITHER HERE OR IN TRAINING LOOP AND SEND\n",
        "\n",
        "        #seq_data is [1,T,F] and non_seq_data is [1, 2 values (alloc and mem)]\n",
        "\n",
        "        seq_data = seq_data.to(self.device)\n",
        "        non_seq_data = non_seq_data.to(self.device)\n",
        "        bhs_dist, ast_to_dom_dist, mem_update_dist, trade_frac_dist, value = self.policynet(seq_data, non_seq_data)\n",
        "\n",
        "        #1. SAMPLING FROM DISTRIBUTIONS\n",
        "        bhs = bhs_dist.sample()\n",
        "        ast_to_dom = ast_to_dom_dist.sample()\n",
        "        mem_update = mem_update_dist.sample()\n",
        "        trade_frac = trade_frac_dist.sample().clamp(0, 1)\n",
        "\n",
        "        #2. CALCULATING LOG PROBS\n",
        "        bhs_logprob = bhs_dist.log_prob(bhs) #need log probabilities for policy gradient calculation\n",
        "\n",
        "        ast_to_dom_logprobs = ast_to_dom_dist.log_prob(ast_to_dom).sum(-1)\n",
        "        #continuous product of probs = continuous sum of log probs\n",
        "        mem_update_logprobs = mem_update_dist.log_prob(mem_update).sum(-1)\n",
        "        trade_frac_logprob = trade_frac_dist.log_prob(trade_frac).sum(-1)\n",
        "\n",
        "        total_logprob = bhs_logprob + ast_to_dom_logprobs + mem_update_logprobs + trade_frac_logprob\n",
        "\n",
        "        return (bhs, ast_to_dom, mem_update, trade_frac), total_logprob, value\n",
        "\n",
        "    def evaluate(self, seq_data, non_seq_data, a1,a2,a3,a4):\n",
        "        \"\"\"Recompute logprobs + entropy + value for PPO update.\"\"\"\n",
        "\n",
        "        #CONCAT MEMORY ONTO NON SEQ DATA - EITHER HERE OR IN TRAINING LOOP AND SEND\n",
        "\n",
        "        seq_data = seq_data.to(self.device)\n",
        "        non_seq_data = non_seq_data.to(self.device)\n",
        "\n",
        "        bhs_dist, atod_dist, mem_dist, trade_frac_dist, value = self.policynet(seq_data, non_seq_data)\n",
        "\n",
        "        bhs_p = bhs_dist.log_prob(a1)\n",
        "        atod_p = atod_dist.log_prob(a2).sum(-1)\n",
        "        mem_upd_p = mem_dist.log_prob(a3).sum(-1)\n",
        "        trade_frac_p = trade_frac_dist.log_prob(a4).sum(-1)\n",
        "\n",
        "        logprob = bhs_p + atod_p + mem_upd_p + trade_frac_p\n",
        "        entropy = (bhs_dist.entropy() + atod_dist.entropy().sum(-1) + mem_dist.entropy().sum(-1)).mean()\n",
        "        return logprob, entropy, value\n",
        "\n",
        "    def update_policy(self, rollouts):\n",
        "\n",
        "        \"\"\"\n",
        "        rollouts should be a dict with:\n",
        "        - seq_data\n",
        "        - non_seq_data\n",
        "        - actions = (a1, a2, a3)\n",
        "        - old_logprobs\n",
        "        - returns\n",
        "        - advantages\n",
        "\n",
        "        this is basically all the data that we stored for the number of episodes during which we\n",
        "        had freezed policy updation. Now we review our calculations.\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        seq_data = rollouts[\"seq_data\"].to(self.device)\n",
        "        non_seq_data = rollouts[\"non_seq_data\"].to(self.device)\n",
        "        bhs = rollouts[\"bhs\"]\n",
        "        ast_to_dom = rollouts[\"ast_to_dom\"]\n",
        "        mem_update = rollouts[\"mem_update\"]\n",
        "        trade_frac = rollouts[\"trade_frac\"]\n",
        "        old_logprobs = rollouts[\"old_logprobs\"].to(self.device)\n",
        "        returns = rollouts[\"rewards\"].to(self.device)\n",
        "        advantages = rollouts[\"values\"].to(self.device)\n",
        "        #returns and advantages calculated in train.py file in training loop\n",
        "\n",
        "        logprobs, entropy, values = self.evaluate(seq_data, non_seq_data, bhs, ast_to_dom, mem_update, trade_frac)\n",
        "        #multiple rows (mini batches) can be evaluated by pytorch just as well as a single row.\n",
        "\n",
        "        ratios = torch.exp(logprobs - old_logprobs)\n",
        "\n",
        "        #if r_t > 1 => new policy assigns higher prob to that action than old policy\n",
        "        #if r_1 < 1 => assigns lower prob\n",
        "\n",
        "        surr1 = ratios * advantages\n",
        "        surr2 = torch.clamp(ratios, 1 - self.clip_eps, 1 + self.clip_eps) * advantages\n",
        "        actor_loss = -torch.min(surr1, surr2).mean()\n",
        "\n",
        "        value_loss = (returns - values).pow(2).mean()\n",
        "        #critic training -> critic learns to estimate return value so we train it using regression (MSE)\n",
        "\n",
        "        loss = actor_loss + self.c1 * value_loss - self.c2* entropy\n",
        "        #entropy increases => loss decreases (supports exploration => higher entropy means more exploration)\n",
        "        #since actor and critic share the same network we backpropagate it with the same loss (thus add it).\n",
        "\n",
        "        #magic statements\n",
        "        self.optimizer.zero_grad()\n",
        "        loss = loss.mean() #taking mean across the entire batch\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(self.policynet.parameters(), max_norm=0.5)\n",
        "        self.optimizer.step()\n",
        "\n",
        "        return {\n",
        "            \"loss\": loss.item(),\n",
        "            \"actor_loss\": actor_loss.item(),\n",
        "            \"value_loss\": value_loss.item(),\n",
        "            \"entropy\": entropy.item()\n",
        "        }\n",
        "\n",
        "class AssetRolloutBuffer:\n",
        "    def __init__(self):\n",
        "        self.seq_data = []\n",
        "        self.non_seq_data = []\n",
        "        self.actions = []\n",
        "        self.logprobs = []\n",
        "        self.values = []\n",
        "        self.rewards = []\n",
        "        self.dones = []\n",
        "\n",
        "    def clear(self):\n",
        "        self.__init__()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHQOrXIT0EuN"
      },
      "source": [
        "## domain agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "y-BVjXUNz7of"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Categorical, Normal\n",
        "#from helpernets import attention_pool\n",
        "\n",
        "class DomainPolicyNet(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            num_assets : int,\n",
        "            h_asset_dim : int,\n",
        "            master_signal_dim : int,\n",
        "            memory_dim : int = 1,\n",
        "            num_signal : int = 2, #signal sent from domain to master\n",
        "            min_std : float = 1e-3,\n",
        "            hidden_dim : int = 128,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.attentionpool = attention_pool(h_asset_dim)\n",
        "\n",
        "        self.shared_net = nn.Linear(h_asset_dim + memory_dim + master_signal_dim, hidden_dim)\n",
        "        self.actor_port_alloc = nn.Linear(hidden_dim, num_assets + 1) #+1 for \"cash\" token for unallocated cash\n",
        "\n",
        "        self.domain_to_master_mean = nn.Linear(hidden_dim, num_signal)\n",
        "        self.domain_to_master_std = nn.Linear(hidden_dim, num_signal)\n",
        "\n",
        "\n",
        "        self.mem_update_mean = nn.Linear(hidden_dim, memory_dim) #actor head 3: memory update value\n",
        "        self.mem_update_std = nn.Linear(hidden_dim, memory_dim)\n",
        "\n",
        "        self.critic = nn.Linear(hidden_dim, 1) #outputs value function\n",
        "        self.min_std = min_std\n",
        "\n",
        "    def forward(self, h_assets, master_signal, mem):\n",
        "\n",
        "        print(MAGENTA + \"master signal: \", master_signal, ENDC)\n",
        "\n",
        "        print(MAGENTA + \"h_assets: \" , h_assets , ENDC)\n",
        "        h_sector, alphas = self.attentionpool(h_assets) #(batch, D) => h_sector\n",
        "        print(YELLOW + \"attention pool done (domain agent)\" + ENDC)\n",
        "        # if mem.dim() == 1:\n",
        "        #     mem = mem.unsqueeze(0)\n",
        "        # if mem.size(0) != h_assets.size(0):\n",
        "        #     mem = mem.expand(h_assets.size(0), -1)\n",
        "\n",
        "        if isinstance(mem, float):\n",
        "            #convert to tensor with batch as first dimension.\n",
        "            mem = torch.tensor([mem], dtype=torch.float32)\n",
        "            mem = mem.unsqueeze(0) #because batch dimension will always be 1\n",
        "\n",
        "\n",
        "        print(BLUE, \"h_sector\", h_sector, ENDC)\n",
        "        print(BLUE, \"master_signal\", master_signal, ENDC)\n",
        "        print(BLUE, \"mem\", mem, ENDC)\n",
        "        net_x = torch.cat([h_sector, master_signal, mem], dim=1) #all the dims other than index 1 should be same.\n",
        "        h = F.relu(self.shared_net(net_x))\n",
        "\n",
        "        #ASSET ALLOCATION (USE DIRICHLET DISTRIBUTION):\n",
        "        logits = self.actor_port_alloc(h)\n",
        "        # logits -> concentration parameters for Dirichlet\n",
        "        raw_alpha = self.actor_port_alloc(h)                   # (batch, num_assets+1)\n",
        "        alpha = F.softplus(raw_alpha) + 1e-3                   # ensure positivity\n",
        "        alloc_distn = torch.distributions.Dirichlet(alpha)\n",
        "\n",
        "        #MEMORY UPDATE SIGNAL\n",
        "        mem_mean = self.mem_update_mean(h) #gives 2 means\n",
        "        mem_logstd = self.mem_update_std(h).clamp(min=torch.log(torch.tensor(self.min_std))) #gives 2 log std\n",
        "        mem_std = mem_logstd.exp() #calculate logstd to ensure that values are positive\n",
        "        mem_update = Normal(mem_mean, mem_std)\n",
        "\n",
        "        #DOMAIN TO MASTER SIGNAL\n",
        "        dtom_mean = self.domain_to_master_mean(h)\n",
        "        dtom_logstd = self.domain_to_master_std(h).clamp(min=torch.log(torch.tensor(self.min_std)))\n",
        "        dtom_std = dtom_logstd.exp()\n",
        "        dtom = Normal(dtom_mean, dtom_std)\n",
        "\n",
        "        value = self.critic(h).squeeze(-1)\n",
        "\n",
        "        return alloc_distn, mem_update, dtom, value\n",
        "\n",
        "class DomainAgent(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            num_assets : int,\n",
        "            h_asset_dim : int,\n",
        "            master_signal_dim : int,\n",
        "            memory_dim : int = 1,\n",
        "            num_signal : int = 2,\n",
        "            min_std : float = 1e-3,\n",
        "            hidden_dim : int = 128,\n",
        "            lr = 3e-4,\n",
        "            clip_eps = 0.2,\n",
        "            c1 = 0.5, #value coefficient (multiplied with L^{value})\n",
        "            c2 = 0.01, #entropy coefficient (multiplied with entropy of action distributions)\n",
        "            device = \"cpu\"\n",
        "    ):\n",
        "\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.policynet = DomainPolicyNet(\n",
        "            num_assets = num_assets,\n",
        "            h_asset_dim = h_asset_dim,\n",
        "            master_signal_dim = master_signal_dim,\n",
        "            memory_dim = memory_dim,\n",
        "            num_signal = num_signal,\n",
        "            min_std = min_std,\n",
        "            hidden_dim = hidden_dim\n",
        "        ).to(device)\n",
        "\n",
        "        self.optimizer = optim.Adam(self.policynet.parameters(), lr=lr)\n",
        "\n",
        "        self.clip_eps = clip_eps\n",
        "        self.c1 = c1\n",
        "        self.c2 = c2\n",
        "\n",
        "        #Initialize memory variables:\n",
        "        self.memory_dim = memory_dim\n",
        "        self.memory = torch.zeros(1, memory_dim, device=device)  # (batch=1, memory_dim)\n",
        "\n",
        "\n",
        "    def act(self, h_assets, master_signal, mem):\n",
        "\n",
        "        h_assets = h_assets.to(self.device) #(batch, num_assets, dim)\n",
        "        master_signal = master_signal.to(self.device)\n",
        "        alloc_distn, mem_update_dist, dtom_dist, value = self.policynet(h_assets, master_signal, mem)\n",
        "\n",
        "        #1. SAMPLING FROM DISTRIBUTIONS\n",
        "        dtom = dtom_dist.sample()\n",
        "        mem_update = mem_update_dist.sample()\n",
        "        allocations = alloc_distn.rsample()                    # (batch, num_assets+1)\n",
        "\n",
        "\n",
        "        #2. CALCULATING LOG PROBS\n",
        "        alloc_log_prob = alloc_distn.log_prob(allocations)\n",
        "        entropy = alloc_distn.entropy()\n",
        "        dtom_logprob = dtom_dist.log_prob(dtom).sum(-1)\n",
        "        mem_update_logprob = mem_update_dist.log_prob(mem_update).sum(-1)\n",
        "\n",
        "        total_logprob = alloc_log_prob + dtom_logprob + mem_update_logprob\n",
        "\n",
        "        return (allocations, dtom, mem_update), total_logprob, value, alloc_distn\n",
        "\n",
        "    def evaluate(self, h_assets, domain_memory, master_signal,alloc, dtom, mem_update):\n",
        "\n",
        "        #recompute values\n",
        "\n",
        "        h_assets = h_assets.to(self.device)\n",
        "        master_signal = master_signal.to(self.device)\n",
        "        alloc_distn, mem_update_dist, dtom_dist, value = self.policynet(h_assets, master_signal, domain_memory)\n",
        "\n",
        "        alloc_p = alloc_distn.log_prob(alloc)\n",
        "        dtom_p = dtom_dist.log_prob(dtom).sum(-1)\n",
        "        mem_upd_p = mem_update_dist.log_prob(mem_update).sum(-1)\n",
        "\n",
        "        logprob = alloc_p + dtom_p + mem_upd_p\n",
        "\n",
        "        alloc_entropy = alloc_distn.entropy()                # (batch,)\n",
        "        dtom_entropy = dtom_dist.entropy().sum(-1)           # (batch,)\n",
        "        mem_entropy = mem_update_dist.entropy().sum(-1)\n",
        "\n",
        "        entropy = alloc_entropy + dtom_entropy + mem_entropy\n",
        "        return logprob, entropy, value\n",
        "\n",
        "    def update_policy(self, rollouts):\n",
        "\n",
        "        \"\"\"\n",
        "            rollouts should be a dict with:\n",
        "            - h_assets\n",
        "            - domain memory\n",
        "            - master agent allocation\n",
        "            - actions = (a1, a2, a3)\n",
        "            - old_logprobs\n",
        "            - returns\n",
        "            - advantages\n",
        "\n",
        "            this is basically all the data that we stored for the number of episodes during which we\n",
        "            had freezed policy updation. Now we review our calculations.\n",
        "            \"\"\"\n",
        "\n",
        "        h_assets = rollouts[\"h_assets\"].to(self.device)\n",
        "        domain_mem = rollouts[\"domain_memory\"].to(self.device)\n",
        "        master_alloc = rollouts[\"master_alloc\"].to(self.device)\n",
        "        alloc = rollouts[\"allocations\"].to(self.device)\n",
        "        dtom = rollouts[\"dtom\"].to(self.device)\n",
        "        mem = rollouts[\"mem_update\"].to(self.device)\n",
        "        old_logprobs = rollouts[\"old_logprobs\"].to(self.device)\n",
        "        returns = rollouts[\"returns\"].to(self.device)\n",
        "        advantages = rollouts[\"advantages\"].to(self.device)\n",
        "        #returns and advantages calculated in train.py file in training loop\n",
        "\n",
        "        logprobs, entropy, values = self.evaluate(h_assets, domain_mem, master_alloc, alloc, dtom, mem)\n",
        "        ratios = torch.exp(logprobs - old_logprobs) #old logprobs are summed up so that new logprobs and old logprobs both are batch first and have same batch value\n",
        "\n",
        "        surr1 = ratios * advantages\n",
        "        surr2 = torch.clamp(ratios, 1 - self.clip_eps, 1 + self.clip_eps) * advantages\n",
        "        actor_loss = -torch.min(surr1, surr2).mean()\n",
        "\n",
        "        value_loss = (returns - values).pow(2).mean() #returns and values are also batch first, deliberately made returns batch wise in buffer addition using unsqueeze(0)\n",
        "        loss = actor_loss + self.c1 * value_loss - self.c2* entropy\n",
        "\n",
        "        #magic statements\n",
        "        self.optimizer.zero_grad()\n",
        "        loss = loss.mean() #taking mean across the entire batch\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(self.policynet.parameters(), max_norm=0.5)\n",
        "        self.optimizer.step()\n",
        "\n",
        "        return {\n",
        "            \"loss\": loss.item(),\n",
        "            \"actor_loss\": actor_loss.mean().item(),\n",
        "            \"value_loss\": value_loss.mean().item(),\n",
        "            \"entropy\": entropy.mean().item()\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsnInPTV0LQG"
      },
      "source": [
        "## masteragent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "DfQDJivF0GpR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Categorical, Normal\n",
        "#from helpernets import attention_pool\n",
        "#MASTER AGENT WILL USE AN INSTANCE OF THE SAME CLASS AS DOMAIN ATTENTION POOL FOR POOLING\n",
        "\n",
        "class MasterPolicyNet(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "           self,\n",
        "           num_domains : int,\n",
        "           h_domain_dim : int,\n",
        "           memory_dim : int = 1,\n",
        "           min_std : float = 1e-3,\n",
        "           hidden_dim : int = 128,\n",
        "\n",
        "    ):\n",
        "\n",
        "        super().__init__()\n",
        "        self.attentionpool = attention_pool(h_domain_dim)\n",
        "\n",
        "        self.shared_net = nn.Linear(h_domain_dim + memory_dim, hidden_dim)\n",
        "        self.actor_port_alloc = nn.Linear(hidden_dim, num_domains + 1) #+1 for \"cash\"\n",
        "\n",
        "        self.mem_update_mean = nn.Linear(hidden_dim, memory_dim) #actor head 3: memory update value\n",
        "        self.mem_update_std = nn.Linear(hidden_dim, memory_dim)\n",
        "\n",
        "        self.critic = nn.Linear(hidden_dim, 1) #outputs value function\n",
        "        self.min_std = min_std\n",
        "\n",
        "    def forward(self, h_domains, mem):\n",
        "\n",
        "        if isinstance(mem, float):\n",
        "            #convert to tensor with batch as first dimension.\n",
        "            mem = torch.tensor([mem], dtype=torch.float32)\n",
        "            mem = mem.unsqueeze(0) #because batch dimension will always be 1\n",
        "\n",
        "        h_master, alphas = self.attentionpool(h_domains) #(batch, D) => h_master\n",
        "        net_x = torch.cat([h_master, mem], dim=1)\n",
        "        h = F.relu(self.shared_net(net_x))\n",
        "\n",
        "        #DOMAIN ALLOCATION (USE DIRICHLET DISTRIBUTION):\n",
        "        logits = self.actor_port_alloc(h)\n",
        "        # logits -> concentration parameters for Dirichlet\n",
        "        raw_alpha = self.actor_port_alloc(h)                   # (batch, num_assets+1)\n",
        "        alpha = F.softplus(raw_alpha) + 1e-3                   # ensure positivity\n",
        "        alloc_distn = torch.distributions.Dirichlet(alpha)\n",
        "\n",
        "        #MEMORY UPDATE SIGNAL\n",
        "        mem_mean = self.mem_update_mean(h) #gives 2 means\n",
        "        mem_logstd = self.mem_update_std(h).clamp(min=torch.log(torch.tensor(self.min_std))) #gives 2 log std\n",
        "        mem_std = mem_logstd.exp() #calculate logstd to ensure that values are positive\n",
        "        mem_update = Normal(mem_mean, mem_std)\n",
        "\n",
        "        value = self.critic(h).squeeze(-1)\n",
        "\n",
        "        return alloc_distn, mem_update, value\n",
        "\n",
        "class MasterAgent(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            num_domains : int,\n",
        "            h_domain_dim : int,\n",
        "            memory_dim : int = 1,\n",
        "            min_std : float = 1e-3,\n",
        "            hidden_dim : int = 128,\n",
        "            lr = 3e-4,\n",
        "            clip_eps = 0.2,\n",
        "            c1 = 0.5, #value coefficient (multiplied with L^{value})\n",
        "            c2 = 0.01, #entropy coefficient (multiplied with entropy of action distributions)\n",
        "            device = \"cpu\"\n",
        "\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.policynet = MasterPolicyNet(\n",
        "            num_domains = num_domains,\n",
        "            h_domain_dim= h_domain_dim,\n",
        "            memory_dim=memory_dim,\n",
        "            min_std=min_std,\n",
        "            hidden_dim=hidden_dim\n",
        "        ).to(device)\n",
        "\n",
        "        self.optimizer = optim.Adam(self.policynet.parameters(), lr=lr)\n",
        "\n",
        "        self.clip_eps = clip_eps\n",
        "        self.c1 = c1\n",
        "        self.c2 = c2\n",
        "\n",
        "        #Initialize memory variables:\n",
        "        self.memory_dim = memory_dim\n",
        "        self.memory = torch.zeros(1, memory_dim, device=device)  # (batch=1, memory_dim)\n",
        "\n",
        "    def act(self, h_domains, mem):\n",
        "\n",
        "        h_domains = h_domains.to(self.device)\n",
        "        alloc_distn, mem_update_dist, value = self.policynet(h_domains,mem)\n",
        "\n",
        "        #1. SAMPLING FROM DISTRIBUTIONS\n",
        "        mem_update = mem_update_dist.sample()\n",
        "        allocations = alloc_distn.rsample()\n",
        "\n",
        "        #2. CALCULATING LOG PROBS\n",
        "        alloc_log_prob = alloc_distn.log_prob(allocations)\n",
        "        entropy = alloc_distn.entropy()\n",
        "        mem_update_logprob = mem_update_dist.log_prob(mem_update).sum(-1)\n",
        "\n",
        "        total_logprob = alloc_log_prob + mem_update_logprob\n",
        "\n",
        "        return (allocations, mem_update), total_logprob, value, alloc_distn\n",
        "\n",
        "    def evaluate(self, h_domains, master_memory, alloc, mem):\n",
        "\n",
        "        h_domains = h_domains.to(self.device)\n",
        "\n",
        "        alloc_distn, mem_update_dist, value = self.policynet(h_domains,master_memory)\n",
        "\n",
        "        alloc_p = alloc_distn.log_prob(alloc)\n",
        "        mem_upd_p = mem_update_dist.log_prob(mem).sum(-1)\n",
        "\n",
        "        logprob = alloc_p + mem_upd_p\n",
        "\n",
        "        alloc_entropy = alloc_distn.entropy()                # (batch,)\n",
        "        mem_entropy = mem_update_dist.entropy().sum(-1)\n",
        "\n",
        "        entropy = alloc_entropy + mem_entropy\n",
        "        return logprob, entropy, value\n",
        "\n",
        "    def update_policy(self, rollouts):\n",
        "\n",
        "        \"\"\"\n",
        "            rollouts should be a dict with:\n",
        "            - h_domains\n",
        "            - master memory\n",
        "            - actions = (a1, a2)\n",
        "            - old_logprobs\n",
        "            - returns\n",
        "            - advantages\n",
        "\n",
        "            this is basically all the data that we stored for the number of episodes during which we\n",
        "            had freezed policy updation. Now we review our calculations.\n",
        "            \"\"\"\n",
        "\n",
        "        h_domains = rollouts[\"h_domains\"].to(self.device)\n",
        "        master_mem = rollouts[\"master_memory\"].to(self.device)\n",
        "        allocations = rollouts[\"allocations\"].to(self.device)\n",
        "        mem_update = rollouts[\"mem_update\"].to(self.device)\n",
        "        old_logprobs = rollouts[\"old_logprobs\"].to(self.device)\n",
        "        returns = rollouts[\"returns\"].to(self.device)\n",
        "        advantages = rollouts[\"advantages\"].to(self.device)\n",
        "        #returns and advantages calculated in train.py file in training loop\n",
        "\n",
        "        logprobs, entropy, values = self.evaluate(h_domains, master_mem, allocations, mem_update)\n",
        "        ratios = torch.exp(logprobs - old_logprobs)\n",
        "\n",
        "        surr1 = ratios * advantages\n",
        "        surr2 = torch.clamp(ratios, 1 - self.clip_eps, 1 + self.clip_eps) * advantages\n",
        "        actor_loss = -torch.min(surr1, surr2).mean()\n",
        "\n",
        "        value_loss = (returns - values).pow(2).mean()\n",
        "        loss = actor_loss + self.c1 * value_loss - self.c2* entropy\n",
        "\n",
        "        #magic statements\n",
        "        self.optimizer.zero_grad()\n",
        "        loss = loss.mean() #taking mean across the entire batch\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(self.policynet.parameters(), max_norm=0.5)\n",
        "\n",
        "        self.optimizer.step()\n",
        "\n",
        "        return {\n",
        "            \"loss\": loss.item(),\n",
        "            \"actor_loss\": actor_loss.mean().item(),\n",
        "            \"value_loss\": value_loss.mean().item(),\n",
        "            \"entropy\": entropy.mean().item()\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFr49sjU0Xh1"
      },
      "source": [
        "# training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1ivNk0TxcfU",
        "outputId": "a87df918-afaa-4931-e74d-759124503f82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92mLoading preprocessed data for AAPL from output_data/AAPL_processed.csv\u001b[0m\n",
            "\u001b[92mLoading preprocessed data for GOOGL from output_data/GOOGL_processed.csv\u001b[0m\n",
            "\u001b[92mLoading preprocessed data for MSFT from output_data/MSFT_processed.csv\u001b[0m\n",
            "\u001b[92mLoading preprocessed data for JPM from output_data/JPM_processed.csv\u001b[0m\n",
            "\u001b[92mLoading preprocessed data for BAC from output_data/BAC_processed.csv\u001b[0m\n",
            "\u001b[92mLoading preprocessed data for GS from output_data/GS_processed.csv\u001b[0m\n",
            "\u001b[92mFinal dataset ready!\u001b[0m\n",
            "dict_keys(['AAPL', 'GOOGL', 'MSFT', 'JPM', 'BAC', 'GS'])\n",
            "\u001b[94m Train data shape:  (3549, 60, 17) \u001b[0m\n",
            "\u001b[92mno of windows, window timesteps, columns\u001b[0m\n",
            "\u001b[94m Test data shape:  (888, 60, 17) \u001b[0m\n",
            "\u001b[94m domain allocs:  [[tensor(0.5000), tensor(0.5000), tensor(0.5000)]] \u001b[0m\n",
            "\u001b[94m asset allocs initialized:  [[tensor(0.1667), tensor(0.1667), tensor(0.1667)], [tensor(0.1667), tensor(0.1667), tensor(0.1667)]] \u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Categorical, Normal\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from arch import arch_model\n",
        "from ta.trend import SMAIndicator, EMAIndicator\n",
        "from ta.volatility import BollingerBands\n",
        "from ta.momentum import RSIIndicator\n",
        "\n",
        "# Import agents and preprocessing\n",
        "# sys.path.append('src/agents')\n",
        "# from asset_level_agent import AssetAgent, AssetRolloutBuffer\n",
        "# from domain_level_agent import DomainAgent\n",
        "# from master_agent import MasterAgent\n",
        "# from helpernets import *\n",
        "# from preprocessing import run  # import only run()\n",
        "\n",
        "RED = '\\033[91m'\n",
        "GREEN = '\\033[92m'\n",
        "YELLOW = '\\033[93m'\n",
        "BLUE = '\\033[94m'\n",
        "ENDC = '\\033[0m'\n",
        "BRIGHT_MAGENTA = '\\033[95m'\n",
        "CYAN = '\\033[96m'\n",
        "WHITE = '\\033[97m'\n",
        "STD_BLUE = '\\033[34m'\n",
        "MAGENTA = '\\033[35m'\n",
        "\n",
        "#----------------------------------------------------------------------------------------\n",
        "#VARIABLES\n",
        "\n",
        "start = \"2007-01-01\"\n",
        "end = \"2024-12-31\"\n",
        "augment = False\n",
        "otpt_show = True\n",
        "batch_size = 20\n",
        "split_ratio = 0.8\n",
        "num_epochs = 10\n",
        "total_portfolio_value = 100000\n",
        "\n",
        "all_tickers = ['AAPL', 'GOOGL', 'MSFT', 'JPM', 'BAC', 'GS']\n",
        "domain_wise_tickers = {\n",
        "    \"Tech\": ['AAPL', 'GOOGL', 'MSFT'],\n",
        "    \"Finance\": ['JPM', 'BAC', 'GS'],\n",
        "}\n",
        "\n",
        "domain_indices = {}\n",
        "asset_indices = {}\n",
        "d = 0\n",
        "\n",
        "#ASSET INDICES MAPPING:\n",
        "for domain, assets in domain_wise_tickers.items():\n",
        "    a = 0\n",
        "    domain_indices[domain] = d\n",
        "    for asset in assets:\n",
        "        asset_indices[asset] = a\n",
        "        a+=1\n",
        "    d +=1\n",
        "\n",
        "num_domains= len(domain_wise_tickers.keys())\n",
        "\n",
        "#----------------------------------------------------------------------------------------\n",
        "#LOADING DATA\n",
        "\n",
        "outdir = \"output_data\"\n",
        "os.makedirs(outdir, exist_ok=True)\n",
        "\n",
        "results = {}\n",
        "missing_tickers = []\n",
        "\n",
        "for ticker in all_tickers:\n",
        "    filename = os.path.join(outdir, f\"{ticker}_processed.csv\")\n",
        "    if os.path.exists(filename):\n",
        "        print(GREEN + f\"Loading preprocessed data for {ticker} from {filename}\" + ENDC)\n",
        "        df = pd.read_csv(filename, index_col=0, parse_dates=True)\n",
        "        results[ticker] = {\"data\": df, \"scalers\": None}  # scalers not saved to CSV\n",
        "    else:\n",
        "        print(YELLOW + f\"No preprocessed file for {ticker}, will run preprocessing\" + ENDC)\n",
        "        missing_tickers.append(ticker)\n",
        "\n",
        "if missing_tickers:\n",
        "    print(BLUE + f\"Running preprocessing for missing tickers: {missing_tickers}\" + ENDC)\n",
        "    new_results = run(missing_tickers, start, end, augment, otpt_show)\n",
        "    results.update(new_results)\n",
        "\n",
        "seq_data = results\n",
        "print(GREEN + \"Final dataset ready!\" + ENDC)\n",
        "print(seq_data.keys())\n",
        "\n",
        "#----------------------------------------------------------------------------------------\n",
        "#PREPARING DATA FOR TRAINING AND TESTING\n",
        "\n",
        "num_seq_cols = len(seq_data[\"AAPL\"][\"data\"].keys())\n",
        "num_seq_rows = len(seq_data[\"AAPL\"][\"data\"])\n",
        "split_idx = int(num_seq_rows * split_ratio)\n",
        "\n",
        "def make_windows(seq_data, window_size = 60):\n",
        "    windows = {}\n",
        "    for asset, info in seq_data.items():\n",
        "\n",
        "        df = info[\"data\"]\n",
        "        data = df.values #numpy array\n",
        "        asset_windows = []\n",
        "        for i in range(len(data) - window_size):\n",
        "            seq = data[i : i+window_size]\n",
        "            asset_windows.append(seq)\n",
        "\n",
        "        windows[asset] = np.array(asset_windows)\n",
        "    return windows, len(windows)\n",
        "\n",
        "def split(windows, split_ratio=0.8):\n",
        "    train_data = {}\n",
        "    test_data = {}\n",
        "    for asset, seqs in windows.items():\n",
        "        n = len(seqs)\n",
        "        split_idx = int(n*split_ratio)\n",
        "        train_data[asset] = seqs[:split_idx]\n",
        "        test_data[asset]  = seqs[split_idx:]\n",
        "    return train_data, test_data\n",
        "\n",
        "\n",
        "window_size = 60\n",
        "all_windows, num_windows = make_windows(seq_data, window_size)\n",
        "train_data, test_data = split(all_windows, split_ratio=0.8)\n",
        "num_episodes = len(train_data[\"AAPL\"].shape)\n",
        "print(BLUE, \"Train data shape: \" , train_data[\"AAPL\"].shape, ENDC) #(no_of_windows, window_timesteps, columns)\n",
        "print(GREEN + \"no of windows, window timesteps, columns\" + ENDC)\n",
        "print(BLUE, \"Test data shape: \", test_data[\"AAPL\"].shape, ENDC)\n",
        "\n",
        "#----------------------------------------------------------------------------------------\n",
        "#DEFINING ARCHITECTURES\n",
        "\n",
        "num_assets = 3\n",
        "\"\"\"number of assets per domain\n",
        "Currently, we assume same number of assets for each domain - later to be changed to where the\n",
        "inputs for pooling layer dimensions obtained \"dynamically\"\n",
        "\n",
        "num_signal = 2 by default (for both asset to domain, domain to master)\n",
        "master sends 1 allocation and domain also does.\"\"\"\n",
        "\n",
        "\n",
        "AssetAG = AssetAgent(seq_input_dim=num_seq_cols, non_seq_input_dim=2)\n",
        "DomainAG = DomainAgent(num_assets, h_asset_dim=2, master_signal_dim=1)\n",
        "MasterAG = MasterAgent(num_domains=2, h_domain_dim=2)\n",
        "\n",
        "AssetBuffer = AssetRolloutBuffer()\n",
        "\n",
        "\n",
        "# After creating agents: AssetAG, DomainAG, MasterAG\n",
        "device_asset = AssetAG.device\n",
        "device_domain = DomainAG.device\n",
        "device_master = MasterAG.device\n",
        "\n",
        "# memory dims (your agents initialize memory_dim attribute)\n",
        "asset_memory_dim = 1\n",
        "domain_memory_dim = DomainAG.memory_dim if hasattr(DomainAG, \"memory_dim\") else 1\n",
        "master_memory_dim = MasterAG.memory_dim if hasattr(MasterAG, \"memory_dim\") else 1\n",
        "\n",
        "# master memory as tensor (batch dim 1)\n",
        "master_mem = torch.zeros(1, master_memory_dim, device=device_master, dtype=torch.float32)\n",
        "\n",
        "# domain memories: list of tensors shaped (1, memory_dim)\n",
        "domain_mem = [\n",
        "    torch.zeros(1, domain_memory_dim, device=device_domain, dtype=torch.float32)\n",
        "    for _ in range(num_domains)\n",
        "]\n",
        "\n",
        "# asset memories: list (per domain) of list (per asset) of tensors (1, memory_dim)\n",
        "asset_mems = []\n",
        "for domain, assets in domain_wise_tickers.items():\n",
        "    am = [torch.zeros(1, asset_memory_dim, device=device_asset, dtype=torch.float32) for _ in assets]\n",
        "    asset_mems.append(am)\n",
        "\n",
        "#ALLOCATIONS ARE IN THE FORM OF RATIOS: TRUE ALLOCATIONS = ALLOCATIONS * PORTFOLIO VALUE\n",
        "\n",
        "# domain_allocs: keep as list of 1-element tensors (shape (1,))\n",
        "# domain_allocs = [\n",
        "#     torch.tensor([1 / num_domains], dtype=torch.float32, device=device_domain)\n",
        "#     for _ in range(num_domains)\n",
        "# ]\n",
        "domain_allocs = []\n",
        "dtemp = [torch.tensor(1 / num_domains) for _ in range(num_domains+1)]\n",
        "domain_allocs.append(dtemp)\n",
        "#a tensor\n",
        "\n",
        "print(BLUE, \"domain allocs: \", domain_allocs, ENDC)\n",
        "\n",
        "# asset_allocs: per-domain list of per-asset 1-element tensors\n",
        "asset_allocs = []\n",
        "for domain_idx, (domain, assets) in enumerate(domain_wise_tickers.items()):\n",
        "    per_domain = [\n",
        "        torch.tensor((1 / num_domains) / len(assets), dtype=torch.float32, device=device_asset)\n",
        "        for _ in assets\n",
        "    ]\n",
        "    asset_allocs.append(per_domain)\n",
        "#an array of tensors\n",
        "\n",
        "print(BLUE, \"asset allocs initialized: \", asset_allocs, ENDC)\n",
        "\n",
        "# current holdings (keep as python numbers or tensors as you prefer)\n",
        "domain_cur_holdings = [0 for _ in range(num_domains)]\n",
        "asset_cur_holdings = [[0 for _ in assets] for assets in domain_wise_tickers.values()]\n",
        "\n",
        "\n",
        "asset_mem_param = 0.7\n",
        "domain_mem_param = 0.7\n",
        "master_mem_param = 0.7\n",
        "\n",
        "#----------------------------------------------------------------------------------------\n",
        "#RETURN ESTIMATIONS:\n",
        "\n",
        "\n",
        "def compute_returns(rewards, gamma=0.99):\n",
        "    returns = []\n",
        "    G = 0.0\n",
        "    for r in reversed(rewards):\n",
        "        G = r + gamma * G\n",
        "        returns.insert(0, G)\n",
        "    return torch.tensor(returns, dtype=torch.float32)\n",
        "\n",
        "#----------------------------------------------------------------------------------------\n",
        "#TRAINING\n",
        "\n",
        "def train():\n",
        "    global domain_allocs, asset_allocs, domain_mem, master_mem\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        #batches- PPO UPDATE OCCURS HERE\n",
        "        print(GREEN + f\"starting epoch {epoch}...\" + ENDC)\n",
        "        for start in range(0, num_windows, batch_size): #generating batches dynamically.\n",
        "\n",
        "            end = start + batch_size\n",
        "            batch_idxs = range(start, min(end, num_windows))\n",
        "\n",
        "            batch_rewards = []\n",
        "            # asset_buffer = {\n",
        "            #     \"seq_data\": [],       # list of tensors: [seq_len, features]\n",
        "            #     \"non_seq_data\": [],   # list of tensors: [non_seq_features]\n",
        "            #     \"actions\": [],        # list of tuples: (a1, a2, a3, a4)\n",
        "            #     \"old_logprobs\": [],   # list of tensors (scalar)\n",
        "            #     \"values\": [],         # list of tensors (scalar)\n",
        "            #     \"rewards\": []         # list of floats\n",
        "            # }\n",
        "            asset_buffer = {}\n",
        "\n",
        "\n",
        "            # domain_buffer = {\n",
        "            #     \"h_assets\" : [],\n",
        "            #     \"domain_memory\" : [],\n",
        "            #     \"master_alloc\" : [],\n",
        "            #     \"actions\" : [],\n",
        "            #     \"old_logprobs\" : [],\n",
        "            #     \"returns\" : [],\n",
        "            #     \"advantages\" : []\n",
        "            # }\n",
        "\n",
        "            domain_buffer = {}\n",
        "\n",
        "            # master_buffer = {\n",
        "            #     \"h_domains\" : [],\n",
        "            #     \"master_memory\" : [],\n",
        "            #     \"actions\" : [],\n",
        "            #     \"old_logprobs\" : [],\n",
        "            #     \"returns\" : [],\n",
        "            #     \"advantages\" : []\n",
        "            # }\n",
        "\n",
        "            master_buffer = {}\n",
        "\n",
        "            for window_idx in batch_idxs:\n",
        "\n",
        "                asset_to_domain_signals = []  # [num_domains][num_assets][ast_to_dom_dim]\n",
        "                domain_to_master_signals = []  # [num_domains,batch, dtom_dim]\n",
        "                master_returns = 0\n",
        "\n",
        "                for domain, assets in domain_wise_tickers.items():\n",
        "                    domain_idx = domain_indices[domain]\n",
        "                    asset_to_domain_sig_domain = []\n",
        "                    r_t_domain = 0.0\n",
        "\n",
        "                    for asset in assets:\n",
        "                        asset_idx = asset_indices[asset]\n",
        "\n",
        "                        seq_tensor = torch.tensor(train_data[asset][window_idx], dtype=torch.float32) #(window timesteps, columns)\n",
        "                        #non_seq_tensor = torch.tensor([asset_allocs[domain_idx][asset_idx], asset_mems[domain_idx][asset_idx]], dtype=torch.float32)\n",
        "\n",
        "                        # print(BLUE + \"asset allocs: \" , asset_allocs[domain_idx][asset_idx] , ENDC)\n",
        "                        # print(BLUE + \"asset mems: \" , asset_mems[domain_idx][asset_idx] , ENDC)\n",
        "\n",
        "                        alloc_val = asset_allocs[domain_idx][asset_idx]  #  this is not batch first when printed.\n",
        "                        mem_val = asset_mems[domain_idx][asset_idx]      # this is in fact batch first.\n",
        "\n",
        "                        if alloc_val.ndim == 1:\n",
        "                            alloc_val = alloc_val.unsqueeze(-1)  # (batch, 1)\n",
        "\n",
        "                        elif alloc_val.ndim == 0:\n",
        "                            alloc_val = alloc_val.unsqueeze(0) .unsqueeze(0) # (batch, 1)\n",
        "                        else:\n",
        "                            pass\n",
        "\n",
        "                        # print(BLUE + \"val allocs: \" , alloc_val , ENDC)\n",
        "                        # print(BLUE + \"val mems: \" , mem_val , ENDC)\n",
        "\n",
        "                        non_seq_tensor = torch.cat([alloc_val, mem_val], dim=-1)  # (batch, 2)\n",
        "\n",
        "                        #1D tensor :- [asset_allocation value, asset memory value]\n",
        "\n",
        "                        seq_in = seq_tensor.unsqueeze(0).to(AssetAG.device)  # [1, T, F]\n",
        "                        #in PPO we are processing data in batches BUT we have to pass each batch instance one at a time, but since\n",
        "                        #pytorch expects data as (batch, ...,...) we need to make faux batches.\n",
        "\n",
        "                        non_seq_in = non_seq_tensor.to(AssetAG.device) #non_seq_tensor.unsqueeze(0).to(AssetAG.device) #(1, 1D tensor)\n",
        "\n",
        "                        # print(RED, \"seq_in shape: \", seq_in.shape, \" non_seq_in shape: \", non_seq_in.shape, ENDC)\n",
        "\n",
        "\n",
        "                        actions, total_logprob, value = AssetAG.act(seq_in, non_seq_in) #put in the form of batch first\n",
        "\n",
        "                        bhs = actions[0].detach()\n",
        "                        ast_to_dom = actions[1].detach() #detach completely removes the new tensor from the current computational graph\n",
        "                        mem_update = actions[2].detach()\n",
        "                        trade_frac = actions[3].detach() #not adding squeeze(0) so the first dimension is still batch.\n",
        "\n",
        "                        with torch.no_grad():\n",
        "\n",
        "\n",
        "                            # reward calc\n",
        "                            p_t = train_data[asset][window_idx+1][0][0] #close price of first timestep of next window\n",
        "                            if window_idx < num_windows - 1:\n",
        "                                p_t_plus_1 = train_data[asset][window_idx][0][0]\n",
        "                                frac = p_t_plus_1 / p_t\n",
        "                                w_asset = asset_allocs[domain_idx][asset_idx]\n",
        "                                # print(YELLOW + f\"Asset: {asset}, p_t: {p_t}, p_t+1: {p_t_plus_1}, frac: {frac}, w_asset: {w_asset}\" + ENDC)\n",
        "                                r_t = w_asset * (frac - 1)\n",
        "                                r_t_domain += r_t\n",
        "\n",
        "                            asset_to_domain_sig_domain.append(ast_to_dom) #(assets, batch, ...) because the first dimension of every ast_to_dom\n",
        "                    #is batch and we are appending various ast_to_doms in the list above.\n",
        "                            asset_mems[domain_idx][asset_idx] += asset_mem_param * mem_update\n",
        "\n",
        "                        #I JUST NEED TO STORE IN ROLLOUTS IN THE SAME FORMAT AS I HAD PASSED INTO ACT() BECAUSE THE UPDATE POLICY ONLY\n",
        "                        #RECREATES THE SCENARIO\n",
        "\n",
        "                        if(len(asset_buffer)==0):\n",
        "                            # print(CYAN + \"First value in rollouts being stored\" + ENDC)\n",
        "                            asset_buffer[\"seq_data\"] = seq_in.clone()\n",
        "                            asset_buffer[\"non_seq_data\"] = non_seq_in.clone()\n",
        "                            asset_buffer[\"bhs\"] = bhs.clone()\n",
        "                            asset_buffer[\"ast_to_dom\"] = ast_to_dom.clone()\n",
        "                            asset_buffer[\"mem_update\"] = mem_update.clone()\n",
        "                            asset_buffer[\"trade_frac\"] = trade_frac.clone()\n",
        "                            asset_buffer[\"old_logprobs\"] = total_logprob.clone()\n",
        "                            asset_buffer[\"values\"] = value.clone()\n",
        "                            # print(CYAN + \"r_t: \", r_t.unsqueeze(0), ENDC)\n",
        "                            asset_buffer[\"rewards\"] = r_t.clone().unsqueeze(0) #need to put this in a batch first format maybe\n",
        "                            # print(CYAN + \"First asset done\" + ENDC)\n",
        "                        else:\n",
        "                            print(RED, \"asset buffer before: \", asset_buffer[\"seq_data\"].shape, ENDC)\n",
        "                            asset_buffer[\"seq_data\"] = torch.cat([asset_buffer[\"seq_data\"], seq_in.clone()], dim=0) #seq_tensor has batch first (batch, window timesteps, columns)\n",
        "                            # print(CYAN + \"seq_in shape stored: \", seq_in, ENDC)\n",
        "                            print(RED, \"asset buffer after: \", asset_buffer[\"seq_data\"].shape, ENDC)\n",
        "                            asset_buffer[\"non_seq_data\"] = torch.cat([asset_buffer[\"non_seq_data\"], non_seq_in.clone()], dim=0)\n",
        "                            asset_buffer[\"bhs\"] = torch.cat([asset_buffer[\"bhs\"], bhs.clone()], dim=0)\n",
        "                            asset_buffer[\"ast_to_dom\"] = torch.cat([asset_buffer[\"ast_to_dom\"], ast_to_dom.clone()], dim=0)\n",
        "                            asset_buffer[\"mem_update\"] = torch.cat([asset_buffer[\"mem_update\"], mem_update.clone()], dim=0)\n",
        "                            asset_buffer[\"trade_frac\"] = torch.cat([asset_buffer[\"trade_frac\"], trade_frac.clone()], dim=0)\n",
        "                            asset_buffer[\"old_logprobs\"] = torch.cat([asset_buffer[\"old_logprobs\"], total_logprob.clone()], dim=0)\n",
        "                            asset_buffer[\"values\"] = torch.cat([asset_buffer[\"values\"], value.clone()], dim=0)\n",
        "                            # print(CYAN + \"r_t: \", r_t.unsqueeze(0), ENDC)\n",
        "                            asset_buffer[\"rewards\"] = torch.cat([asset_buffer[\"rewards\"], r_t.clone().unsqueeze(0)], dim=0) #need to put this in a batch first format maybe\n",
        "                            # print(CYAN + \"Asset done\" + ENDC)\n",
        "\n",
        "                    # if isinstance(asset_to_domain_sig_domain, list):\n",
        "                    #     if isinstance(asset_to_domain_sig_domain[0], torch.Tensor):\n",
        "                    #         asset_to_domain_sig_domain = torch.stack(asset_to_domain_sig_domain)\n",
        "                    #         #joins all the elements of the array along dimension 0 (stack) => batch stack\n",
        "                    #     else:\n",
        "                    #         asset_to_domain_sig_domain = torch.tensor(asset_to_domain_sig_domain, dtype=torch.float32)\n",
        "\n",
        "                    #i am skipping this block because i want to keep everything batch first to ensure uniformity\n",
        "                    with torch.no_grad():\n",
        "                        asset_to_domain_sig_domain = (\n",
        "                            torch.stack(asset_to_domain_sig_domain)    # (num_assets, batch, dim)\n",
        "                            .permute(1, 0, 2)                          # → (batch, num_assets, dim)\n",
        "                            .to(DomainAG.device)\n",
        "                        )\n",
        "\n",
        "                        # if not asset_to_domain_sig_domain:\n",
        "                        #     # Make a dummy tensor if empty to prevent crash\n",
        "                        #     asset_to_domain_sig_domain = torch.zeros(\n",
        "                        #         (1, len(domain_wise_tickers[domain]), DomainAG.h_asset_dim),\n",
        "                        #         device=DomainAG.device\n",
        "                        #     )\n",
        "                        # else:\n",
        "                        #     asset_to_domain_sig_domain = (\n",
        "                        #         torch.stack(asset_to_domain_sig_domain)\n",
        "                        #         .permute(1, 0, 2)\n",
        "                        #         .to(DomainAG.device)\n",
        "                        #     )\n",
        "\n",
        "                    # print(CYAN, \"asset to domain sig domain stacked\" , asset_to_domain_sig_domain, ENDC)\n",
        "                    alloc_val = domain_allocs[0][domain_idx]  #  this is not batch first when printed.\n",
        "                    # print(GREEN, \"alloc val: \", alloc_val, ENDC)\n",
        "\n",
        "                    if alloc_val.ndim == 1:\n",
        "                        alloc_val = alloc_val.unsqueeze(0)  # (batch, 1)\n",
        "\n",
        "                    elif alloc_val.ndim == 0:\n",
        "                        alloc_val = alloc_val.unsqueeze(0).unsqueeze(0) # (batch, 1) => adding 2 dims to match h_assets\n",
        "                    elif alloc_val.ndim == 3:\n",
        "                        alloc_val = alloc_val.squeeze(0)  #remove extra dim if already present\n",
        "                    else:\n",
        "                            pass\n",
        "                    # print(GREEN, \"alloc val: \", alloc_val, ENDC)\n",
        "                    # print(BLUE + \"h_assets: \" , asset_to_domain_sig_domain , ENDC)\n",
        "                    actions, total_logprob, value, alloc_distn = DomainAG.act(asset_to_domain_sig_domain, alloc_val, domain_mem[domain_idx])\n",
        "\n",
        "                    with torch.no_grad():\n",
        "                        allocations = actions[0].detach() #Keeping batch dimensions\n",
        "                        print(GREEN , \"all allocations (domain output)\" , allocations, ENDC)\n",
        "                        dtom = actions[1].detach()\n",
        "                        mem_update = actions[2].detach()\n",
        "\n",
        "                        asset_allocs[domain_idx] = allocations.squeeze(0)  #remove batch dim\n",
        "                        domain_mem[domain_idx] += domain_mem_param * mem_update\n",
        "\n",
        "                        if(len(domain_buffer)==0):\n",
        "                            # print(CYAN, \"First value in domain rollouts being stored: h_assets \", asset_to_domain_sig_domain, ENDC)\n",
        "                            domain_buffer[\"h_assets\"] = asset_to_domain_sig_domain.detach()\n",
        "                            domain_buffer[\"domain_memory\"] = domain_mem[domain_idx].detach()\n",
        "                            domain_buffer[\"master_alloc\"] = alloc_val.detach()\n",
        "                            domain_buffer[\"allocations\"] = allocations.detach()\n",
        "                            domain_buffer[\"dtom\"] = dtom.detach()\n",
        "                            domain_buffer[\"mem_update\"] = mem_update.detach()\n",
        "                            domain_buffer[\"returns\"] = r_t_domain.detach().unsqueeze(0)\n",
        "                            domain_buffer[\"old_logprobs\"] = total_logprob.detach()\n",
        "                            domain_buffer[\"advantages\"] = value.detach()\n",
        "                        else:\n",
        "                            # print(CYAN, \"Next value in domain rollouts being stored: h_assets \", asset_to_domain_sig_domain, ENDC)\n",
        "                            domain_buffer[\"h_assets\"] = torch.cat([domain_buffer[\"h_assets\"], asset_to_domain_sig_domain.detach()], dim=0)\n",
        "                            # print(CYAN + \"domain h_assets shape stored: \", asset_to_domain_sig_domain, ENDC)\n",
        "                            domain_buffer[\"domain_memory\"] = torch.cat([domain_buffer[\"domain_memory\"], domain_mem[domain_idx].detach()], dim=0)\n",
        "                            domain_buffer[\"master_alloc\"] = torch.cat([domain_buffer[\"master_alloc\"], alloc_val.detach()], dim=0)\n",
        "                            domain_buffer[\"allocations\"] = torch.cat([domain_buffer[\"allocations\"], allocations.detach()], dim=0)\n",
        "                            domain_buffer[\"dtom\"] = torch.cat([domain_buffer[\"dtom\"], dtom.detach()], dim=0)\n",
        "                            domain_buffer[\"mem_update\"] = torch.cat([domain_buffer[\"mem_update\"], mem_update.detach()], dim=0)\n",
        "                            domain_buffer[\"returns\"] = torch.cat([domain_buffer[\"returns\"], torch.tensor(r_t_domain).detach().unsqueeze(0)], dim=0)\n",
        "                            domain_buffer[\"old_logprobs\"] = torch.cat([domain_buffer[\"old_logprobs\"], total_logprob.detach()], dim=0)\n",
        "                            domain_buffer[\"advantages\"] = torch.cat([domain_buffer[\"advantages\"], value.detach()], dim=0)\n",
        "\n",
        "\n",
        "                        domain_to_master_signals.append(dtom)\n",
        "                        master_returns += domain_allocs[0][domain_idx] * r_t_domain\n",
        "                        print(MAGENTA + \"domain done\" + ENDC)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    # master\n",
        "                    domain_to_master_signals = (\n",
        "                            torch.stack(domain_to_master_signals)    # [num_domains,batch, dtom_dim]\n",
        "                            .permute(1, 0, 2)                          # → (batch, num_domains, dtom_dim)\n",
        "                            .to(MasterAG.device)\n",
        "                    )\n",
        "\n",
        "                master_actions, total_logprob, value, alloc_distn = MasterAG.act(domain_to_master_signals, master_mem)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    allocations = master_actions[0].detach()  #keeping batch first => that's why not applying squeeze(0)\n",
        "                    mem_update = master_actions[1].detach()\n",
        "                    domain_allocs = allocations #keep as it is                     #DOUBT HERE ******\n",
        "                    print(GREEN , \"all allocations (master output)\" , allocations, ENDC)\n",
        "                    master_mem += master_mem_param * mem_update\n",
        "\n",
        "                    if(len(master_buffer)==0):\n",
        "                        # print(MAGENTA, \"First value in master rollouts being stored: h_assets \", asset_to_domain_sig_domain, ENDC)\n",
        "                        master_buffer[\"h_domains\"] = domain_to_master_signals.detach()\n",
        "                        master_buffer[\"master_memory\"] = master_mem.detach()\n",
        "                        master_buffer[\"allocations\"] = allocations.detach()\n",
        "                        master_buffer[\"mem_update\"] = mem_update.detach()\n",
        "                        master_buffer[\"returns\"] = master_returns.detach().unsqueeze(0)\n",
        "                        master_buffer[\"old_logprobs\"] = total_logprob.detach()\n",
        "                        master_buffer[\"advantages\"] = value.detach()\n",
        "                    else:\n",
        "                        # print(MAGENTA, \"Next value in master rollouts being stored: h_assets \", domain_to_master_signals, ENDC)\n",
        "                        master_buffer[\"h_domains\"] = torch.cat([master_buffer[\"h_domains\"], domain_to_master_signals.detach()], dim=0)\n",
        "                        master_buffer[\"master_memory\"] = torch.cat([master_buffer[\"master_memory\"], master_mem.detach()], dim=0)\n",
        "                        master_buffer[\"allocations\"] = torch.cat([master_buffer[\"allocations\"], allocations.detach()], dim=0)\n",
        "                        master_buffer[\"mem_update\"] = torch.cat([master_buffer[\"mem_update\"], mem_update.detach()], dim=0)\n",
        "                        master_buffer[\"returns\"] = torch.cat([master_buffer[\"returns\"], torch.tensor(master_returns).detach().unsqueeze(0)], dim=0)\n",
        "                        master_buffer[\"old_logprobs\"] = torch.cat([master_buffer[\"old_logprobs\"], total_logprob.detach()], dim=0)\n",
        "                        master_buffer[\"advantages\"] = torch.cat([master_buffer[\"advantages\"], value.detach()], dim=0)\n",
        "\n",
        "                print(WHITE + f\"one asset-domain-master cycle (window: {window_idx}) done -----------------------------------------------------\" + ENDC)\n",
        "\n",
        "\n",
        "            print(BRIGHT_MAGENTA + \"upadating all agents\" + ENDC)\n",
        "            AssetAG.update_policy(asset_buffer)\n",
        "            print(MAGENTA + \"asset agent updated\" + ENDC)\n",
        "            DomainAG.update_policy(domain_buffer)\n",
        "            print(MAGENTA + \"domain agent updated\" + ENDC)\n",
        "            MasterAG.update_policy(master_buffer)\n",
        "            print(BRIGHT_MAGENTA + \"updates done!\" + ENDC)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_data[\"AAPL\"][\"data\"].keys()"
      ],
      "metadata": {
        "id": "jERgfs4bXafF",
        "outputId": "4d55f3ef-7c47-45e4-d7a4-934058f72d24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['close', 'high', 'low', 'open', 'volume', 'return', 'volatility',\n",
              "       'momentum', 'SMA_10', 'EMA_10', 'RSI_14', 'BB_High', 'BB_Low',\n",
              "       'Log_Returns', 'Volatility_10', 'Hurst', 'GARCH_Vol'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeCjbblQtWbG",
        "outputId": "04cc5d83-dbf9-46c2-9383-d357df6d796a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92mstarting epoch 0...\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([1, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([2, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([2, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([3, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.5000]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.9197,  0.6746],\n",
            "         [-0.3599,  1.2104],\n",
            "         [-1.5007,  1.4691]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.5220, 1.6478]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.5220, 1.6478]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.5000]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[0.]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.3839, 0.1371, 0.3135, 0.1656]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([3, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([4, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([4, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([5, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([5, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([6, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.5000]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.4475,  0.3195],\n",
            "         [-1.4038, -0.3255],\n",
            "         [ 0.3533,  0.1617]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.4429, 0.8269]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.4429, 0.8269]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.5000]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[0.]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.1766, 0.2398, 0.0130, 0.5706]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.3115,  1.1053]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.3030, 0.0495, 0.6476]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 0) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([6, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([7, 60, 17]) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2246194989.py:456: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  domain_buffer[\"returns\"] = torch.cat([domain_buffer[\"returns\"], torch.tensor(r_t_domain).detach().unsqueeze(0)], dim=0)\n",
            "/tmp/ipython-input-2246194989.py:497: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  master_buffer[\"returns\"] = torch.cat([master_buffer[\"returns\"], torch.tensor(master_returns).detach().unsqueeze(0)], dim=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[91m asset buffer before:  torch.Size([7, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([8, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([8, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([9, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.3030]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.0252,  0.3754],\n",
            "         [-0.3694,  1.0179],\n",
            "         [-0.2295,  0.2936]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.6650, 1.0546]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.6650, 1.0546]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.3030]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[0.4211]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.2044, 0.0154, 0.0884, 0.6918]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([9, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([10, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([10, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([11, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([11, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([12, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.0495]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.8878,  0.1258],\n",
            "         [-0.4279, -0.9225],\n",
            "         [ 0.4821, -0.5633]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.5226, 0.3349]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.5226, 0.3349]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.0495]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[0.3658]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.5158, 0.1335, 0.3082, 0.0426]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.7586,  0.7062]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.9820, 0.0162, 0.0019]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 1) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([12, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([13, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([13, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([14, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([14, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([15, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.9820]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.7976, -0.0752],\n",
            "         [ 1.3725,  2.5087],\n",
            "         [-0.4859, -0.6413]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.6255, 0.9310]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.6255, 0.9310]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.9820]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[0.9451]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.1281, 0.5849, 0.2512, 0.0358]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([15, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([16, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([16, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([17, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([17, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([18, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.0162]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.4000, -2.0702],\n",
            "         [-0.1042,  1.1238],\n",
            "         [-0.5317,  1.0007]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.5274, 0.7057]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.5274, 0.7057]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.0162]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-0.2804]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.0577, 0.0930, 0.4765, 0.3727]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-1.3608,  0.1486]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.1411, 0.8298, 0.0290]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 2) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([18, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([19, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([19, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([20, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([20, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([21, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.1411]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-1.7482,  0.5563],\n",
            "         [ 0.5068,  1.2008],\n",
            "         [ 0.0724,  1.6149]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.6818, 1.4500]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.6818, 1.4500]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.1411]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[1.2386]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.2464, 0.0006, 0.3924, 0.3606]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([21, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([22, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([22, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([23, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([23, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([24, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.8298]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.7167, -0.5180],\n",
            "         [ 1.4359,  0.1358],\n",
            "         [-0.1615,  0.2454]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.5751, 0.6228]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.5751, 0.6228]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.8298]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[0.1935]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.0106, 0.3061, 0.6581, 0.0253]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.6723,  0.1438]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.9503, 0.0038, 0.0459]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 3) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([24, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([25, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([25, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([26, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([26, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([27, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.9503]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 1.5549,  0.5523],\n",
            "         [-0.4781,  0.8187],\n",
            "         [-0.5036,  1.8328]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.9569, 1.2065]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.9569, 1.2065]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.9503]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[0.2979]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.0985, 0.1018, 0.2040, 0.5958]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([27, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([28, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([28, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([29, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([29, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([30, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.0038]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.3058, -0.6498],\n",
            "         [ 0.3249,  1.6695],\n",
            "         [ 1.6889,  0.4602]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.8984, 0.7082]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.8984, 0.7082]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.0038]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[0.2816]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.0047, 0.0605, 0.9181, 0.0167]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.5281,  0.0291]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[8.1297e-04, 9.8362e-01, 1.5571e-02]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 4) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([30, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([31, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([31, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([32, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([32, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([33, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.0008]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.8238, -0.1865],\n",
            "         [-1.4445,  0.5660],\n",
            "         [-0.0254,  1.4193]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.3979, 1.3057]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.3979, 1.3057]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.0008]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-0.6594]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.0125, 0.8572, 0.0835, 0.0468]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([33, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([34, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([34, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([35, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([35, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([36, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.9836]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.8084,  1.4822],\n",
            "         [-0.3730, -0.4170],\n",
            "         [ 0.4522,  2.1090]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.9679, 1.0673]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.9679, 1.0673]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.9836]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-0.0737]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.1830, 0.0881, 0.5934, 0.1355]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-1.2774, -0.0571]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.7996, 0.1059, 0.0945]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 5) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[95mupadating all agents\u001b[0m\n",
            "\u001b[35masset agent updated\u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[5.0000e-01],\n",
            "        [5.0000e-01],\n",
            "        [3.0295e-01],\n",
            "        [4.9470e-02],\n",
            "        [9.8195e-01],\n",
            "        [1.6179e-02],\n",
            "        [1.4113e-01],\n",
            "        [8.2982e-01],\n",
            "        [9.5034e-01],\n",
            "        [3.7704e-03],\n",
            "        [8.1297e-04],\n",
            "        [9.8362e-01]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.9197,  0.6746],\n",
            "         [-0.3599,  1.2104],\n",
            "         [-1.5007,  1.4691]],\n",
            "\n",
            "        [[ 0.4475,  0.3195],\n",
            "         [-1.4038, -0.3255],\n",
            "         [ 0.3533,  0.1617]],\n",
            "\n",
            "        [[ 0.0252,  0.3754],\n",
            "         [-0.3694,  1.0179],\n",
            "         [-0.2295,  0.2936]],\n",
            "\n",
            "        [[ 0.8878,  0.1258],\n",
            "         [-0.4279, -0.9225],\n",
            "         [ 0.4821, -0.5633]],\n",
            "\n",
            "        [[-0.7976, -0.0752],\n",
            "         [ 1.3725,  2.5087],\n",
            "         [-0.4859, -0.6413]],\n",
            "\n",
            "        [[ 0.4000, -2.0702],\n",
            "         [-0.1042,  1.1238],\n",
            "         [-0.5317,  1.0007]],\n",
            "\n",
            "        [[-1.7482,  0.5563],\n",
            "         [ 0.5068,  1.2008],\n",
            "         [ 0.0724,  1.6149]],\n",
            "\n",
            "        [[-0.7167, -0.5180],\n",
            "         [ 1.4359,  0.1358],\n",
            "         [-0.1615,  0.2454]],\n",
            "\n",
            "        [[ 1.5549,  0.5523],\n",
            "         [-0.4781,  0.8187],\n",
            "         [-0.5036,  1.8328]],\n",
            "\n",
            "        [[-0.3058, -0.6498],\n",
            "         [ 0.3249,  1.6695],\n",
            "         [ 1.6889,  0.4602]],\n",
            "\n",
            "        [[-0.8238, -0.1865],\n",
            "         [-1.4445,  0.5660],\n",
            "         [-0.0254,  1.4193]],\n",
            "\n",
            "        [[ 0.8084,  1.4822],\n",
            "         [-0.3730, -0.4170],\n",
            "         [ 0.4522,  2.1090]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.5220, 1.6478],\n",
            "        [0.4429, 0.8269],\n",
            "        [0.6650, 1.0546],\n",
            "        [0.5226, 0.3349],\n",
            "        [0.6255, 0.9310],\n",
            "        [0.5274, 0.7057],\n",
            "        [0.6818, 1.4500],\n",
            "        [0.5751, 0.6228],\n",
            "        [0.9569, 1.2065],\n",
            "        [0.8984, 0.7082],\n",
            "        [0.3979, 1.3057],\n",
            "        [0.9679, 1.0673]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.5220, 1.6478],\n",
            "        [0.4429, 0.8269],\n",
            "        [0.6650, 1.0546],\n",
            "        [0.5226, 0.3349],\n",
            "        [0.6255, 0.9310],\n",
            "        [0.5274, 0.7057],\n",
            "        [0.6818, 1.4500],\n",
            "        [0.5751, 0.6228],\n",
            "        [0.9569, 1.2065],\n",
            "        [0.8984, 0.7082],\n",
            "        [0.3979, 1.3057],\n",
            "        [0.9679, 1.0673]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[5.0000e-01],\n",
            "        [5.0000e-01],\n",
            "        [3.0295e-01],\n",
            "        [4.9470e-02],\n",
            "        [9.8195e-01],\n",
            "        [1.6179e-02],\n",
            "        [1.4113e-01],\n",
            "        [8.2982e-01],\n",
            "        [9.5034e-01],\n",
            "        [3.7704e-03],\n",
            "        [8.1297e-04],\n",
            "        [9.8362e-01]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[ 0.4211],\n",
            "        [ 0.3658],\n",
            "        [ 0.9451],\n",
            "        [-0.2804],\n",
            "        [ 1.2386],\n",
            "        [ 0.1935],\n",
            "        [ 0.2979],\n",
            "        [ 0.2816],\n",
            "        [-0.6594],\n",
            "        [-0.0737],\n",
            "        [-0.6634],\n",
            "        [-0.0148]]) \u001b[0m\n",
            "\u001b[35mdomain agent updated\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.3115,  1.1053],\n",
            "        [-0.7586,  0.7062],\n",
            "        [-1.3608,  0.1486],\n",
            "        [-0.6723,  0.1438],\n",
            "        [-0.5281,  0.0291],\n",
            "        [-1.2774, -0.0571]], grad_fn=<SumBackward1>)\n",
            "\u001b[95mupdates done!\u001b[0m\n",
            "\u001b[92mstarting epoch 1...\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([1, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([2, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([2, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([3, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.7996]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-1.2153, -0.9615],\n",
            "         [-0.2733, -1.2136],\n",
            "         [ 0.2458,  1.5967]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.2548, 0.7217]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.2548, 0.7217]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.7996]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-0.6634]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.2090, 0.5829, 0.1727, 0.0353]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([3, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([4, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([4, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([5, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([5, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([6, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.1059]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.2129, -0.4658],\n",
            "         [-0.0921,  1.4325],\n",
            "         [ 0.9114,  0.8206]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.8859, 0.8458]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.8859, 0.8458]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.1059]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-0.0148]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.0115, 0.0585, 0.1989, 0.7312]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.5639, -0.1573]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.0475, 0.1088, 0.8438]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 0) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([6, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([7, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([7, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([8, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([8, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([9, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.0475]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.2590,  0.6203],\n",
            "         [-0.3997,  0.7476],\n",
            "         [ 0.1957,  0.1904]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.7383, 0.9518]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.7383, 0.9518]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.0475]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-0.7621]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.0438, 0.0850, 0.0433, 0.8279]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([9, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([10, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([10, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([11, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([11, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([12, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.1088]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-4.7750e-03, -6.9273e-01],\n",
            "         [ 1.3715e-03,  1.9756e+00],\n",
            "         [ 1.2256e+00,  7.4532e-01]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.9161, 0.8503]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.9161, 0.8503]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.1088]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-0.6791]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.4330, 0.0064, 0.0620, 0.4987]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.3549, -0.0452]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.1391, 0.5107, 0.3502]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 1) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([12, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([13, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([13, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([14, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([14, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([15, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.1391]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-4.8479e-01,  1.1356e+00],\n",
            "         [ 6.3010e-04, -5.8505e-02],\n",
            "         [-1.6669e+00,  1.1561e-01]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.3579, 1.2043]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.3579, 1.2043]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.1391]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-1.0209]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.3433, 0.1585, 0.0081, 0.4901]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([15, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([16, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([16, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([17, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([17, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([18, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.5107]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-1.1120,  0.7878],\n",
            "         [-0.5460, -0.7841],\n",
            "         [-1.9553,  0.7317]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.1311, 1.3287]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.1311, 1.3287]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.5107]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-1.1027]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[2.0385e-01, 3.2855e-04, 7.1909e-01, 7.6731e-02]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[1.3698, 1.8413]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.0976, 0.7516, 0.1508]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 2) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([18, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([19, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([19, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([20, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([20, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([21, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.0976]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.3011,  0.8827],\n",
            "         [-0.3149, -0.4408],\n",
            "         [ 0.7006, -1.0026]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.5146, 0.5930]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.5146, 0.5930]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.0976]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-1.6917]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.0187, 0.1430, 0.4965, 0.3418]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([21, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([22, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([22, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([23, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([23, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([24, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.7516]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.2363, -0.7989],\n",
            "         [-1.3030, -0.9570],\n",
            "         [-0.0690, -1.0238]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.0864, 0.4009]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.0864, 0.4009]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.7516]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-1.7182]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.2837, 0.0506, 0.5379, 0.1278]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.3672, 1.3352]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.7235, 0.2439, 0.0326]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 3) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([24, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([25, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([25, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([26, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([26, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([27, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.7235]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.3657, -1.2402],\n",
            "         [ 1.6659,  1.2415],\n",
            "         [-0.2765,  1.2881]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.8873, 0.6589]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.8873, 0.6589]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.7235]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-1.4510]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.1365, 0.3633, 0.1454, 0.3549]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([27, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([28, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([28, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([29, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([29, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([30, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.2439]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-1.0452, -1.7799],\n",
            "         [ 0.7534,  1.2314],\n",
            "         [ 0.0025,  1.3559]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.4868, 0.7972]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.4868, 0.7972]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.2439]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-1.4706]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.0912, 0.2864, 0.3261, 0.2962]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[1.0150, 1.6092]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.3038, 0.5439, 0.1523]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 4) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([30, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([31, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([31, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([32, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([32, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([33, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.3038]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-2.9044,  0.2863],\n",
            "         [ 0.3688,  1.2882],\n",
            "         [ 0.0999,  1.1370]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.3434, 1.5676]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.3434, 1.5676]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.3038]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-1.8440]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.2523, 0.0833, 0.1466, 0.5179]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([33, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([34, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([34, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([35, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([35, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([36, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.5439]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.7264, -1.5404],\n",
            "         [ 0.3050,  0.0098],\n",
            "         [ 1.3181,  1.4663]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.8425, 0.3188]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.8425, 0.3188]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.5439]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-1.4970]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.0322, 0.2719, 0.1918, 0.5041]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.1817, 1.1537]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.2990, 0.2383, 0.4626]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 5) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[95mupadating all agents\u001b[0m\n",
            "\u001b[35masset agent updated\u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.7996],\n",
            "        [0.1059],\n",
            "        [0.0475],\n",
            "        [0.1088],\n",
            "        [0.1391],\n",
            "        [0.5107],\n",
            "        [0.0976],\n",
            "        [0.7516],\n",
            "        [0.7235],\n",
            "        [0.2439],\n",
            "        [0.3038],\n",
            "        [0.5439]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-1.2153e+00, -9.6145e-01],\n",
            "         [-2.7334e-01, -1.2136e+00],\n",
            "         [ 2.4583e-01,  1.5967e+00]],\n",
            "\n",
            "        [[ 2.1294e-01, -4.6577e-01],\n",
            "         [-9.2090e-02,  1.4325e+00],\n",
            "         [ 9.1136e-01,  8.2060e-01]],\n",
            "\n",
            "        [[ 2.5900e-01,  6.2028e-01],\n",
            "         [-3.9968e-01,  7.4760e-01],\n",
            "         [ 1.9574e-01,  1.9037e-01]],\n",
            "\n",
            "        [[-4.7750e-03, -6.9273e-01],\n",
            "         [ 1.3715e-03,  1.9756e+00],\n",
            "         [ 1.2256e+00,  7.4532e-01]],\n",
            "\n",
            "        [[-4.8479e-01,  1.1356e+00],\n",
            "         [ 6.3010e-04, -5.8505e-02],\n",
            "         [-1.6669e+00,  1.1561e-01]],\n",
            "\n",
            "        [[-1.1120e+00,  7.8777e-01],\n",
            "         [-5.4598e-01, -7.8413e-01],\n",
            "         [-1.9553e+00,  7.3169e-01]],\n",
            "\n",
            "        [[-3.0107e-01,  8.8269e-01],\n",
            "         [-3.1491e-01, -4.4078e-01],\n",
            "         [ 7.0060e-01, -1.0026e+00]],\n",
            "\n",
            "        [[ 2.3632e-01, -7.9894e-01],\n",
            "         [-1.3030e+00, -9.5701e-01],\n",
            "         [-6.8963e-02, -1.0238e+00]],\n",
            "\n",
            "        [[ 3.6574e-01, -1.2402e+00],\n",
            "         [ 1.6659e+00,  1.2415e+00],\n",
            "         [-2.7653e-01,  1.2881e+00]],\n",
            "\n",
            "        [[-1.0452e+00, -1.7799e+00],\n",
            "         [ 7.5341e-01,  1.2314e+00],\n",
            "         [ 2.5069e-03,  1.3559e+00]],\n",
            "\n",
            "        [[-2.9044e+00,  2.8626e-01],\n",
            "         [ 3.6876e-01,  1.2882e+00],\n",
            "         [ 9.9853e-02,  1.1370e+00]],\n",
            "\n",
            "        [[ 7.2639e-01, -1.5404e+00],\n",
            "         [ 3.0496e-01,  9.7925e-03],\n",
            "         [ 1.3181e+00,  1.4663e+00]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.2548, 0.7217],\n",
            "        [0.8859, 0.8458],\n",
            "        [0.7383, 0.9518],\n",
            "        [0.9161, 0.8503],\n",
            "        [0.3579, 1.2043],\n",
            "        [0.1311, 1.3287],\n",
            "        [0.5146, 0.5930],\n",
            "        [0.0864, 0.4009],\n",
            "        [0.8873, 0.6589],\n",
            "        [0.4868, 0.7972],\n",
            "        [0.3434, 1.5676],\n",
            "        [0.8425, 0.3188]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.2548, 0.7217],\n",
            "        [0.8859, 0.8458],\n",
            "        [0.7383, 0.9518],\n",
            "        [0.9161, 0.8503],\n",
            "        [0.3579, 1.2043],\n",
            "        [0.1311, 1.3287],\n",
            "        [0.5146, 0.5930],\n",
            "        [0.0864, 0.4009],\n",
            "        [0.8873, 0.6589],\n",
            "        [0.4868, 0.7972],\n",
            "        [0.3434, 1.5676],\n",
            "        [0.8425, 0.3188]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.7996],\n",
            "        [0.1059],\n",
            "        [0.0475],\n",
            "        [0.1088],\n",
            "        [0.1391],\n",
            "        [0.5107],\n",
            "        [0.0976],\n",
            "        [0.7516],\n",
            "        [0.7235],\n",
            "        [0.2439],\n",
            "        [0.3038],\n",
            "        [0.5439]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-0.7621],\n",
            "        [-0.6791],\n",
            "        [-1.0209],\n",
            "        [-1.1027],\n",
            "        [-1.6917],\n",
            "        [-1.7182],\n",
            "        [-1.4510],\n",
            "        [-1.4706],\n",
            "        [-1.8440],\n",
            "        [-1.4970],\n",
            "        [-1.2078],\n",
            "        [-1.3712]]) \u001b[0m\n",
            "\u001b[35mdomain agent updated\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.5639, -0.1573],\n",
            "        [-0.3549, -0.0452],\n",
            "        [ 1.3698,  1.8413],\n",
            "        [ 0.3672,  1.3352],\n",
            "        [ 1.0150,  1.6092],\n",
            "        [ 0.1817,  1.1537]], grad_fn=<SumBackward1>)\n",
            "\u001b[95mupdates done!\u001b[0m\n",
            "\u001b[92mstarting epoch 2...\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([1, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([2, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([2, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([3, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.2990]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.1442, -1.2206],\n",
            "         [-1.0011,  0.9648],\n",
            "         [-1.1418, -1.6544]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.0178, 0.6642]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.0178, 0.6642]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.2990]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-1.2078]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.1902, 0.2305, 0.2318, 0.3475]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([3, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([4, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([4, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([5, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([5, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([6, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.2383]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.1508, -1.2285],\n",
            "         [-0.8960, -0.3272],\n",
            "         [-1.3185, -0.8034]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.0244,  0.6310]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[-0.0244,  0.6310]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.2383]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-1.3712]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.2546, 0.1151, 0.0513, 0.5790]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.5579,  0.0033]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.0186, 0.3839, 0.5976]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 0) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([6, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([7, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([7, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([8, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([8, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([9, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.0186]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 1.2538, -0.2412],\n",
            "         [-0.3943, -0.5402],\n",
            "         [-0.4529,  0.0158]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.5103, 0.5367]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.5103, 0.5367]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.0186]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-1.9050]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.0448, 0.0618, 0.7227, 0.1708]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([9, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([10, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([10, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([11, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([11, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([12, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.3839]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.3806, -0.1650],\n",
            "         [-0.6105, -0.8000],\n",
            "         [ 1.8685, -0.1642]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.4951, 0.4322]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.4951, 0.4322]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.3839]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-1.8641]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.0113, 0.8098, 0.1008, 0.0782]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.2856, 0.7255]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.2807, 0.7164, 0.0030]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 1) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([12, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([13, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([13, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([14, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([14, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([15, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.2807]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.7803, -1.3898],\n",
            "         [ 0.2983,  0.2331],\n",
            "         [-0.4153,  0.5515]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.5949, 0.5092]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.5949, 0.5092]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.2807]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-1.6953]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.3146, 0.1977, 0.4854, 0.0024]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([15, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([16, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([16, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([17, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([17, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([18, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.7164]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.3466,  1.7320],\n",
            "         [-0.7357,  1.5823],\n",
            "         [ 0.5397, -0.2392]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.8178, 1.2973]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.8178, 1.2973]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.7164]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-1.8232]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.0969, 0.3344, 0.2509, 0.3178]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[1.0881, 1.9935]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.5496, 0.4070, 0.0434]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 2) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([18, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([19, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([19, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([20, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([20, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([21, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.5496]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.0587,  0.9665],\n",
            "         [-1.0590, -1.1098],\n",
            "         [-1.0595, -1.4766]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.0301, 0.6787]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.0301, 0.6787]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.5496]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-1.7996]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.1514, 0.2157, 0.5928, 0.0400]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([21, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([22, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([22, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([23, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([23, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([24, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.4070]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.1132,  0.0663],\n",
            "         [ 1.3388, -0.3768],\n",
            "         [-0.3403, -0.6997]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.5538, 0.4250]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.5538, 0.4250]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.4070]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-0.8355]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.4970, 0.3507, 0.0921, 0.0602]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.0735,  0.7175]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.1175, 0.5809, 0.3016]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 3) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([24, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([25, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([25, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([26, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([26, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([27, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.1175]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.4618,  0.9211],\n",
            "         [ 1.2665, -0.7754],\n",
            "         [ 2.2042,  0.8263]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[1.0334, 0.5015]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[1.0334, 0.5015]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.1175]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-2.2115]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.3400, 0.0022, 0.3452, 0.3126]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([27, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([28, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([28, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([29, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([29, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([30, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.5809]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.0423, -0.9705],\n",
            "         [-1.8693,  0.2151],\n",
            "         [ 0.9928, -1.1711]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.2073, 0.5775]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.2073, 0.5775]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.5809]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-0.3797]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.1100, 0.4531, 0.0172, 0.4197]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.1862, 0.4385]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.1613, 0.2026, 0.6360]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 4) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([30, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([31, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([31, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([32, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([32, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([33, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.1613]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.3401,  1.8804],\n",
            "         [ 0.2649,  1.0064],\n",
            "         [-0.8397, -0.5871]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.7128, 1.0761]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.7128, 1.0761]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.1613]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-2.6386]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.6402, 0.0141, 0.1053, 0.2404]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([33, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([34, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([34, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([35, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([35, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([36, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.2026]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.4561,  1.8563],\n",
            "         [-1.6534, -0.3143],\n",
            "         [ 1.2470,  0.7147]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.6692, 1.0907]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.6692, 1.0907]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.2026]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-0.2104]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.0014, 0.3443, 0.0572, 0.5971]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[1.3970, 1.5478]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.6024, 0.3783, 0.0193]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 5) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[95mupadating all agents\u001b[0m\n",
            "\u001b[35masset agent updated\u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.2990],\n",
            "        [0.2383],\n",
            "        [0.0186],\n",
            "        [0.3839],\n",
            "        [0.2807],\n",
            "        [0.7164],\n",
            "        [0.5496],\n",
            "        [0.4070],\n",
            "        [0.1175],\n",
            "        [0.5809],\n",
            "        [0.1613],\n",
            "        [0.2026]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.1442, -1.2206],\n",
            "         [-1.0011,  0.9648],\n",
            "         [-1.1418, -1.6544]],\n",
            "\n",
            "        [[-0.1508, -1.2285],\n",
            "         [-0.8960, -0.3272],\n",
            "         [-1.3185, -0.8034]],\n",
            "\n",
            "        [[ 1.2538, -0.2412],\n",
            "         [-0.3943, -0.5402],\n",
            "         [-0.4529,  0.0158]],\n",
            "\n",
            "        [[-0.3806, -0.1650],\n",
            "         [-0.6105, -0.8000],\n",
            "         [ 1.8685, -0.1642]],\n",
            "\n",
            "        [[ 0.7803, -1.3898],\n",
            "         [ 0.2983,  0.2331],\n",
            "         [-0.4153,  0.5515]],\n",
            "\n",
            "        [[-0.3466,  1.7320],\n",
            "         [-0.7357,  1.5823],\n",
            "         [ 0.5397, -0.2392]],\n",
            "\n",
            "        [[-0.0587,  0.9665],\n",
            "         [-1.0590, -1.1098],\n",
            "         [-1.0595, -1.4766]],\n",
            "\n",
            "        [[-0.1132,  0.0663],\n",
            "         [ 1.3388, -0.3768],\n",
            "         [-0.3403, -0.6997]],\n",
            "\n",
            "        [[-0.4618,  0.9211],\n",
            "         [ 1.2665, -0.7754],\n",
            "         [ 2.2042,  0.8263]],\n",
            "\n",
            "        [[ 0.0423, -0.9705],\n",
            "         [-1.8693,  0.2151],\n",
            "         [ 0.9928, -1.1711]],\n",
            "\n",
            "        [[ 0.3401,  1.8804],\n",
            "         [ 0.2649,  1.0064],\n",
            "         [-0.8397, -0.5871]],\n",
            "\n",
            "        [[ 0.4561,  1.8563],\n",
            "         [-1.6534, -0.3143],\n",
            "         [ 1.2470,  0.7147]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[ 0.0178,  0.6642],\n",
            "        [-0.0244,  0.6310],\n",
            "        [ 0.5103,  0.5367],\n",
            "        [ 0.4951,  0.4322],\n",
            "        [ 0.5949,  0.5092],\n",
            "        [ 0.8178,  1.2973],\n",
            "        [ 0.0301,  0.6787],\n",
            "        [ 0.5538,  0.4250],\n",
            "        [ 1.0334,  0.5015],\n",
            "        [ 0.2073,  0.5775],\n",
            "        [ 0.7128,  1.0761],\n",
            "        [ 0.6692,  1.0907]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[ 0.0178,  0.6642],\n",
            "        [-0.0244,  0.6310],\n",
            "        [ 0.5103,  0.5367],\n",
            "        [ 0.4951,  0.4322],\n",
            "        [ 0.5949,  0.5092],\n",
            "        [ 0.8178,  1.2973],\n",
            "        [ 0.0301,  0.6787],\n",
            "        [ 0.5538,  0.4250],\n",
            "        [ 1.0334,  0.5015],\n",
            "        [ 0.2073,  0.5775],\n",
            "        [ 0.7128,  1.0761],\n",
            "        [ 0.6692,  1.0907]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.2990],\n",
            "        [0.2383],\n",
            "        [0.0186],\n",
            "        [0.3839],\n",
            "        [0.2807],\n",
            "        [0.7164],\n",
            "        [0.5496],\n",
            "        [0.4070],\n",
            "        [0.1175],\n",
            "        [0.5809],\n",
            "        [0.1613],\n",
            "        [0.2026]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-1.9050],\n",
            "        [-1.8641],\n",
            "        [-1.6953],\n",
            "        [-1.8232],\n",
            "        [-1.7996],\n",
            "        [-0.8355],\n",
            "        [-2.2115],\n",
            "        [-0.3797],\n",
            "        [-2.6386],\n",
            "        [-0.2104],\n",
            "        [-3.3400],\n",
            "        [-0.6161]]) \u001b[0m\n",
            "\u001b[35mdomain agent updated\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.5579,  0.0033],\n",
            "        [ 0.2856,  0.7255],\n",
            "        [ 1.0881,  1.9935],\n",
            "        [-0.0735,  0.7175],\n",
            "        [ 0.1862,  0.4385],\n",
            "        [ 1.3970,  1.5478]], grad_fn=<SumBackward1>)\n",
            "\u001b[95mupdates done!\u001b[0m\n",
            "\u001b[92mstarting epoch 3...\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([1, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([2, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([2, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([3, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.6024]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.4342, -0.1852],\n",
            "         [ 0.4365, -1.3716],\n",
            "         [-0.7493, -1.8999]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.1724, 0.0834]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.1724, 0.0834]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.6024]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-3.3400]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.1354, 0.1411, 0.3370, 0.3865]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([3, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([4, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([4, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([5, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([5, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([6, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.3783]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.1278,  0.8828],\n",
            "         [-0.1677,  0.5519],\n",
            "         [-0.2425, -0.0744]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.6653, 0.9540]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.6653, 0.9540]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.3783]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-0.6161]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.2556, 0.1128, 0.2311, 0.4006]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.2934,  0.1646]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[3.3553e-01, 9.6731e-05, 6.6437e-01]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 0) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([6, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([7, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([7, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([8, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([8, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([9, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.3355]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-1.4654,  0.5121],\n",
            "         [ 0.0371,  1.2415],\n",
            "         [ 0.6341,  0.1144]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.6108, 1.1524]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.6108, 1.1524]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.3355]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-2.8514]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.1212, 0.6087, 0.1020, 0.1681]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([9, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([10, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([10, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([11, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([11, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([12, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[9.6731e-05]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.5471,  1.5207],\n",
            "         [-1.2507, -0.2574],\n",
            "         [-0.5109,  0.7433]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.5408, 1.1869]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.5408, 1.1869]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[9.6731e-05]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-0.2615]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.3372, 0.6126, 0.0370, 0.0132]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-1.2697,  0.0494]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.0858, 0.5836, 0.3306]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 1) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([12, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([13, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([13, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([14, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([14, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([15, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.0858]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.8792,  1.3868],\n",
            "         [ 1.4534, -0.0683],\n",
            "         [ 0.5912,  0.9895]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[1.2228, 0.6852]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[1.2228, 0.6852]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.0858]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-3.1744]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.0128, 0.8073, 0.1206, 0.0593]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([15, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([16, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([16, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([17, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([17, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([18, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.5836]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-1.0025,  1.4374],\n",
            "         [-1.7328, -0.2328],\n",
            "         [ 0.5084,  0.3020]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.3546, 1.2767]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.3546, 1.2767]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.5836]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-0.7358]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[1.5956e-02, 9.3535e-01, 4.8326e-02, 3.6540e-04]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-1.4985, -0.1629]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.7060, 0.0299, 0.2640]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 2) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([18, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([19, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([19, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([20, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([20, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([21, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.7060]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.0042, -1.2876],\n",
            "         [-0.7636,  0.1288],\n",
            "         [-1.9806, -2.1955]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.2540,  0.4955]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[-0.2540,  0.4955]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.7060]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-3.3706]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.1580, 0.2511, 0.0104, 0.5805]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([21, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([22, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([22, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([23, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([23, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([24, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.0299]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.5673,  1.6762],\n",
            "         [-2.2921,  0.1820],\n",
            "         [ 0.6290, -0.5642]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.3129, 1.2788]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.3129, 1.2788]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.0299]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[0.0028]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.5898, 0.0052, 0.3461, 0.0589]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.8645,  0.7673]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.5286, 0.4361, 0.0353]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 3) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([24, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([25, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([25, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([26, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([26, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([27, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.5286]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[1.4826, 0.1066],\n",
            "         [0.1016, 0.9982],\n",
            "         [1.2032, 0.7507]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[1.1473, 0.6461]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[1.1473, 0.6461]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.5286]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-3.2672]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.5243, 0.4440, 0.0241, 0.0076]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([27, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([28, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([28, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([29, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([29, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([30, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.4361]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.6537, -1.0318],\n",
            "         [-0.7578, -1.7467],\n",
            "         [-1.0904,  1.8230]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.2632, 0.6850]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.2632, 0.6850]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.4361]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[0.1040]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.0287, 0.0733, 0.2249, 0.6732]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[1.3906, 1.6619]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.1568, 0.4296, 0.4135]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 4) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([30, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([31, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([31, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([32, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([32, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([33, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.1568]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.6562,  0.8484],\n",
            "         [-0.3233,  1.0916],\n",
            "         [ 1.4050,  0.4714]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.8526, 1.0866]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.8526, 1.0866]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.1568]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-3.2424]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.0557, 0.0350, 0.0310, 0.8782]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([33, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([34, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([34, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([35, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([35, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([36, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.4296]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.2749, -1.1457],\n",
            "         [ 0.4149, -0.8884],\n",
            "         [-0.0889, -1.1208]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.2320, 0.1558]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.2320, 0.1558]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.4296]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[0.2089]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.3506, 0.0116, 0.6113, 0.0266]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.9336, 2.0599]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.0146, 0.9123, 0.0731]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 5) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[95mupadating all agents\u001b[0m\n",
            "\u001b[35masset agent updated\u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[6.0242e-01],\n",
            "        [3.7831e-01],\n",
            "        [3.3553e-01],\n",
            "        [9.6731e-05],\n",
            "        [8.5771e-02],\n",
            "        [5.8365e-01],\n",
            "        [7.0602e-01],\n",
            "        [2.9948e-02],\n",
            "        [5.2855e-01],\n",
            "        [4.3614e-01],\n",
            "        [1.5683e-01],\n",
            "        [4.2963e-01]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.4342, -0.1852],\n",
            "         [ 0.4365, -1.3716],\n",
            "         [-0.7493, -1.8999]],\n",
            "\n",
            "        [[ 0.1278,  0.8828],\n",
            "         [-0.1677,  0.5519],\n",
            "         [-0.2425, -0.0744]],\n",
            "\n",
            "        [[-1.4654,  0.5121],\n",
            "         [ 0.0371,  1.2415],\n",
            "         [ 0.6341,  0.1144]],\n",
            "\n",
            "        [[ 0.5471,  1.5207],\n",
            "         [-1.2507, -0.2574],\n",
            "         [-0.5109,  0.7433]],\n",
            "\n",
            "        [[ 0.8792,  1.3868],\n",
            "         [ 1.4534, -0.0683],\n",
            "         [ 0.5912,  0.9895]],\n",
            "\n",
            "        [[-1.0025,  1.4374],\n",
            "         [-1.7328, -0.2328],\n",
            "         [ 0.5084,  0.3020]],\n",
            "\n",
            "        [[-0.0042, -1.2876],\n",
            "         [-0.7636,  0.1288],\n",
            "         [-1.9806, -2.1955]],\n",
            "\n",
            "        [[-0.5673,  1.6762],\n",
            "         [-2.2921,  0.1820],\n",
            "         [ 0.6290, -0.5642]],\n",
            "\n",
            "        [[ 1.4826,  0.1066],\n",
            "         [ 0.1016,  0.9982],\n",
            "         [ 1.2032,  0.7507]],\n",
            "\n",
            "        [[ 0.6537, -1.0318],\n",
            "         [-0.7578, -1.7467],\n",
            "         [-1.0904,  1.8230]],\n",
            "\n",
            "        [[-0.6562,  0.8484],\n",
            "         [-0.3233,  1.0916],\n",
            "         [ 1.4050,  0.4714]],\n",
            "\n",
            "        [[-0.2749, -1.1457],\n",
            "         [ 0.4149, -0.8884],\n",
            "         [-0.0889, -1.1208]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[ 0.1724,  0.0834],\n",
            "        [ 0.6653,  0.9540],\n",
            "        [ 0.6108,  1.1524],\n",
            "        [ 0.5408,  1.1869],\n",
            "        [ 1.2228,  0.6852],\n",
            "        [ 0.3546,  1.2767],\n",
            "        [-0.2540,  0.4955],\n",
            "        [ 0.3129,  1.2788],\n",
            "        [ 1.1473,  0.6461],\n",
            "        [ 0.2632,  0.6850],\n",
            "        [ 0.8526,  1.0866],\n",
            "        [ 0.2320,  0.1558]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[ 0.1724,  0.0834],\n",
            "        [ 0.6653,  0.9540],\n",
            "        [ 0.6108,  1.1524],\n",
            "        [ 0.5408,  1.1869],\n",
            "        [ 1.2228,  0.6852],\n",
            "        [ 0.3546,  1.2767],\n",
            "        [-0.2540,  0.4955],\n",
            "        [ 0.3129,  1.2788],\n",
            "        [ 1.1473,  0.6461],\n",
            "        [ 0.2632,  0.6850],\n",
            "        [ 0.8526,  1.0866],\n",
            "        [ 0.2320,  0.1558]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[6.0242e-01],\n",
            "        [3.7831e-01],\n",
            "        [3.3553e-01],\n",
            "        [9.6731e-05],\n",
            "        [8.5771e-02],\n",
            "        [5.8365e-01],\n",
            "        [7.0602e-01],\n",
            "        [2.9948e-02],\n",
            "        [5.2855e-01],\n",
            "        [4.3614e-01],\n",
            "        [1.5683e-01],\n",
            "        [4.2963e-01]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-2.8514e+00],\n",
            "        [-2.6153e-01],\n",
            "        [-3.1744e+00],\n",
            "        [-7.3580e-01],\n",
            "        [-3.3706e+00],\n",
            "        [ 2.8195e-03],\n",
            "        [-3.2672e+00],\n",
            "        [ 1.0401e-01],\n",
            "        [-3.2424e+00],\n",
            "        [ 2.0892e-01],\n",
            "        [-3.5024e+00],\n",
            "        [ 1.1362e-01]]) \u001b[0m\n",
            "\u001b[35mdomain agent updated\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.2934,  0.1646],\n",
            "        [-1.2697,  0.0494],\n",
            "        [-1.4985, -0.1629],\n",
            "        [-0.8645,  0.7673],\n",
            "        [ 1.3906,  1.6619],\n",
            "        [ 0.9336,  2.0599]], grad_fn=<SumBackward1>)\n",
            "\u001b[95mupdates done!\u001b[0m\n",
            "\u001b[92mstarting epoch 4...\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([1, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([2, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([2, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([3, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.0146]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.2538, -1.8734],\n",
            "         [-1.3373, -0.7332],\n",
            "         [-1.1224,  0.8451]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.0116,  0.7608]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[-0.0116,  0.7608]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.0146]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-3.5024]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.6287, 0.1556, 0.0207, 0.1950]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([3, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([4, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([4, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([5, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([5, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([6, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.9123]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-1.1600, -1.2824],\n",
            "         [-0.0459, -0.3089],\n",
            "         [ 0.2574,  0.3565]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.2491, 0.6032]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.2491, 0.6032]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.9123]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[0.1136]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.0028, 0.3977, 0.0333, 0.5662]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.4077,  0.5031]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.7112, 0.2486, 0.0402]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 0) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([6, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([7, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([7, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([8, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([8, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([9, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.7112]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.7381, -0.6215],\n",
            "         [-0.6368,  1.1509],\n",
            "         [ 0.1723,  0.1946]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.6826, 0.7965]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.6826, 0.7965]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.7112]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-3.8584]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[8.3393e-02, 8.4140e-01, 7.4980e-02, 2.2541e-04]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([9, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([10, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([10, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([11, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([11, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([12, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.2486]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.3340,  0.0785],\n",
            "         [-0.6969,  0.0962],\n",
            "         [ 0.3372, -0.7196]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.4965, 0.6160]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.4965, 0.6160]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.2486]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-0.0414]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.3679, 0.2326, 0.0872, 0.3124]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.2172,  0.1408]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.0194, 0.2590, 0.7217]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 1) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([12, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([13, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([13, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([14, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([14, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([15, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.0194]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.0195, -1.6426],\n",
            "         [-0.3858,  0.7624],\n",
            "         [ 1.4250, -1.2122]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.4637, 0.2196]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.4637, 0.2196]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.0194]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-4.2233]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.0875, 0.4892, 0.0631, 0.3601]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([15, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([16, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([16, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([17, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([17, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([18, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.2590]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.0550,  0.2016],\n",
            "         [-0.9309,  0.0789],\n",
            "         [ 0.6700,  0.1668]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.5459, 0.8308]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.5459, 0.8308]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.2590]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-0.0303]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.9162, 0.0359, 0.0298, 0.0181]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.9183, -0.0866]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.2534, 0.4905, 0.2561]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 2) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([18, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([19, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([19, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([20, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([20, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([21, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.2534]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 1.8455, -1.0554],\n",
            "         [-0.0306, -0.4433],\n",
            "         [ 0.1911,  1.2953]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.8058, 0.4146]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.8058, 0.4146]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.2534]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-3.5602]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.0227, 0.0490, 0.7737, 0.1547]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([21, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([22, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([22, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([23, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([23, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([24, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.4905]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.3274, -1.9556],\n",
            "         [ 0.1208, -1.5885],\n",
            "         [ 0.0049, -0.8863]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[ 0.0587, -0.0325]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[ 0.0587, -0.0325]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.4905]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[0.0191]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.1054, 0.1920, 0.2964, 0.4063]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.2353, 1.3956]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.0132, 0.9091, 0.0778]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 3) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([24, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([25, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([25, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([26, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([26, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([27, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.0132]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 2.6962, -0.3880],\n",
            "         [ 1.2773,  2.3100],\n",
            "         [ 0.0893,  0.4430]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[1.3331, 0.5785]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[1.3331, 0.5785]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.0132]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-3.5378]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.1906, 0.6301, 0.1147, 0.0646]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([27, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([28, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([28, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([29, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([29, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([30, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.9091]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-1.2760,  1.2135],\n",
            "         [ 1.5480,  0.9891],\n",
            "         [-1.8666, -0.2613]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.4012, 1.3102]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.4012, 1.3102]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.9091]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[0.7244]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.2239, 0.0648, 0.4919, 0.2194]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.5280,  0.8810]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.3723, 0.3117, 0.3160]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 4) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([30, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([31, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([31, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([32, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([32, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([33, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.3723]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.9297, -1.0827],\n",
            "         [ 0.2051,  0.1760],\n",
            "         [-0.5612, -1.3849]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.1068, 0.4694]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.1068, 0.4694]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.3723]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-3.0352]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.5017, 0.3370, 0.1138, 0.0475]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([33, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([34, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([34, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([35, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([35, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([36, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.3117]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-1.1394,  1.4468],\n",
            "         [-0.2808,  0.0449],\n",
            "         [-1.4101, -1.6534]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.1012, 1.0122]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.1012, 1.0122]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.3117]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[0.3202]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.1247, 0.0599, 0.5229, 0.2925]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[1.8733, 2.2887]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.5168, 0.4305, 0.0527]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 5) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[95mupadating all agents\u001b[0m\n",
            "\u001b[35masset agent updated\u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.0146],\n",
            "        [0.9123],\n",
            "        [0.7112],\n",
            "        [0.2486],\n",
            "        [0.0194],\n",
            "        [0.2590],\n",
            "        [0.2534],\n",
            "        [0.4905],\n",
            "        [0.0132],\n",
            "        [0.9091],\n",
            "        [0.3723],\n",
            "        [0.3117]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.2538, -1.8734],\n",
            "         [-1.3373, -0.7332],\n",
            "         [-1.1224,  0.8451]],\n",
            "\n",
            "        [[-1.1600, -1.2824],\n",
            "         [-0.0459, -0.3089],\n",
            "         [ 0.2574,  0.3565]],\n",
            "\n",
            "        [[ 0.7381, -0.6215],\n",
            "         [-0.6368,  1.1509],\n",
            "         [ 0.1723,  0.1946]],\n",
            "\n",
            "        [[ 0.3340,  0.0785],\n",
            "         [-0.6969,  0.0962],\n",
            "         [ 0.3372, -0.7196]],\n",
            "\n",
            "        [[-0.0195, -1.6426],\n",
            "         [-0.3858,  0.7624],\n",
            "         [ 1.4250, -1.2122]],\n",
            "\n",
            "        [[-0.0550,  0.2016],\n",
            "         [-0.9309,  0.0789],\n",
            "         [ 0.6700,  0.1668]],\n",
            "\n",
            "        [[ 1.8455, -1.0554],\n",
            "         [-0.0306, -0.4433],\n",
            "         [ 0.1911,  1.2953]],\n",
            "\n",
            "        [[-0.3274, -1.9556],\n",
            "         [ 0.1208, -1.5885],\n",
            "         [ 0.0049, -0.8863]],\n",
            "\n",
            "        [[ 2.6962, -0.3880],\n",
            "         [ 1.2773,  2.3100],\n",
            "         [ 0.0893,  0.4430]],\n",
            "\n",
            "        [[-1.2760,  1.2135],\n",
            "         [ 1.5480,  0.9891],\n",
            "         [-1.8666, -0.2613]],\n",
            "\n",
            "        [[-0.9297, -1.0827],\n",
            "         [ 0.2051,  0.1760],\n",
            "         [-0.5612, -1.3849]],\n",
            "\n",
            "        [[-1.1394,  1.4468],\n",
            "         [-0.2808,  0.0449],\n",
            "         [-1.4101, -1.6534]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.0116,  0.7608],\n",
            "        [ 0.2491,  0.6032],\n",
            "        [ 0.6826,  0.7965],\n",
            "        [ 0.4965,  0.6160],\n",
            "        [ 0.4637,  0.2196],\n",
            "        [ 0.5459,  0.8308],\n",
            "        [ 0.8058,  0.4146],\n",
            "        [ 0.0587, -0.0325],\n",
            "        [ 1.3331,  0.5785],\n",
            "        [ 0.4012,  1.3102],\n",
            "        [ 0.1068,  0.4694],\n",
            "        [ 0.1012,  1.0122]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[-0.0116,  0.7608],\n",
            "        [ 0.2491,  0.6032],\n",
            "        [ 0.6826,  0.7965],\n",
            "        [ 0.4965,  0.6160],\n",
            "        [ 0.4637,  0.2196],\n",
            "        [ 0.5459,  0.8308],\n",
            "        [ 0.8058,  0.4146],\n",
            "        [ 0.0587, -0.0325],\n",
            "        [ 1.3331,  0.5785],\n",
            "        [ 0.4012,  1.3102],\n",
            "        [ 0.1068,  0.4694],\n",
            "        [ 0.1012,  1.0122]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.0146],\n",
            "        [0.9123],\n",
            "        [0.7112],\n",
            "        [0.2486],\n",
            "        [0.0194],\n",
            "        [0.2590],\n",
            "        [0.2534],\n",
            "        [0.4905],\n",
            "        [0.0132],\n",
            "        [0.9091],\n",
            "        [0.3723],\n",
            "        [0.3117]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-3.8584],\n",
            "        [-0.0414],\n",
            "        [-4.2233],\n",
            "        [-0.0303],\n",
            "        [-3.5602],\n",
            "        [ 0.0191],\n",
            "        [-3.5378],\n",
            "        [ 0.7244],\n",
            "        [-3.0352],\n",
            "        [ 0.3202],\n",
            "        [-2.6712],\n",
            "        [ 0.1620]]) \u001b[0m\n",
            "\u001b[35mdomain agent updated\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.4077,  0.5031],\n",
            "        [-0.2172,  0.1408],\n",
            "        [-0.9183, -0.0866],\n",
            "        [ 0.2353,  1.3956],\n",
            "        [-0.5280,  0.8810],\n",
            "        [ 1.8733,  2.2887]], grad_fn=<SumBackward1>)\n",
            "\u001b[95mupdates done!\u001b[0m\n",
            "\u001b[92mstarting epoch 5...\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([1, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([2, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([2, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([3, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.5168]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.5185,  0.6336],\n",
            "         [-0.4327, -0.3273],\n",
            "         [ 0.1112,  0.4723]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.5232, 0.9350]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.5232, 0.9350]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.5168]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-2.6712]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.6070, 0.0277, 0.2806, 0.0847]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([3, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([4, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([4, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([5, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([5, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([6, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.4305]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.6005,  1.8067],\n",
            "         [ 0.8244,  2.1839],\n",
            "         [ 1.0352,  0.4566]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[1.1949, 1.2924]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[1.1949, 1.2924]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.4305]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[0.1620]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.0071, 0.0956, 0.5733, 0.3240]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.1390,  1.4275]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.0600, 0.9343, 0.0057]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 0) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([6, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([7, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([7, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([8, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([8, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([9, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.0600]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.0853,  0.4099],\n",
            "         [-1.6021,  0.8162],\n",
            "         [-0.2524,  0.5223]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.4829, 1.2600]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.4829, 1.2600]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.0600]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-2.7934]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.2297, 0.1621, 0.0146, 0.5935]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([9, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([10, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([10, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([11, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([11, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([12, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.9343]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.4386, -1.5372],\n",
            "         [ 0.5441,  0.5265],\n",
            "         [ 1.0132, -0.8705]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.4746, 0.2099]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.4746, 0.2099]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.9343]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[0.3335]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.5640, 0.0266, 0.3365, 0.0730]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-1.3256,  0.0830]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.0082, 0.0935, 0.8983]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 1) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([12, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([13, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([13, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([14, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([14, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([15, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.0082]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.3288, -0.7082],\n",
            "         [ 1.6481, -0.8028],\n",
            "         [-1.2763, -0.0682]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.4421, 0.4170]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.4421, 0.4170]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.0082]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-3.4872]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.3753, 0.5726, 0.0323, 0.0198]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([15, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([16, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([16, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([17, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([17, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([18, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.0935]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.6233,  1.3688],\n",
            "         [-0.1759,  0.4173],\n",
            "         [-0.3586,  0.6468]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.8173, 1.0871]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.8173, 1.0871]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.0935]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[0.3789]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[9.1191e-01, 7.6288e-04, 1.7792e-02, 6.9538e-02]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.0095,  0.8360]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.0138, 0.7985, 0.1878]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 2) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([18, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([19, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([19, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([20, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([20, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([21, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.0138]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.4021,  2.1406],\n",
            "         [ 0.7446,  0.4877],\n",
            "         [-0.3293,  0.3803]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.8773, 1.2020]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.8773, 1.2020]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.0138]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-3.4381]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.4474, 0.3067, 0.1989, 0.0471]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([21, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([22, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([22, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([23, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([23, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([24, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.7985]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.8322,  1.0421],\n",
            "         [-0.4010,  1.5813],\n",
            "         [-0.3361, -0.4511]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.5678, 1.2578]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.5678, 1.2578]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.7985]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[0.3877]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.0021, 0.4101, 0.5637, 0.0241]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.4097,  0.4180]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.0119, 0.5649, 0.4232]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 3) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([24, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([25, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([25, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([26, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([26, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([27, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.0119]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.5803,  0.9855],\n",
            "         [ 0.2127,  1.7527],\n",
            "         [-1.6323, -0.0922]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.6289, 1.2590]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.6289, 1.2590]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.0119]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-3.9004]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.2114, 0.7151, 0.0329, 0.0406]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([27, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([28, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([28, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([29, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([29, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([30, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.5649]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.1440,  0.8325],\n",
            "         [-1.3355, -1.3837],\n",
            "         [-1.4907,  1.2253]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.1965, 1.1519]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.1965, 1.1519]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.5649]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[0.2126]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.7944, 0.1413, 0.0316, 0.0328]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.5499,  0.4332]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.2532, 0.5838, 0.1630]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 4) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([30, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([31, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([31, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([32, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([32, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([33, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.2532]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-1.2580,  0.5864],\n",
            "         [-0.0068,  0.7390],\n",
            "         [ 0.8866, -0.5756]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.5701, 0.9175]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.5701, 0.9175]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.2532]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-2.7629]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.4139, 0.3041, 0.2585, 0.0235]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([33, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([34, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([34, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([35, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([35, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([36, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.5838]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.4093,  0.2066],\n",
            "         [-2.0928, -0.6787],\n",
            "         [-0.1491,  1.3294]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.1929, 1.1921]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.1929, 1.1921]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.5838]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[0.1541]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.1154, 0.6380, 0.0089, 0.2378]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.7132, -0.2521]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.0081, 0.7835, 0.2084]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 5) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[95mupadating all agents\u001b[0m\n",
            "\u001b[35masset agent updated\u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.5168],\n",
            "        [0.4305],\n",
            "        [0.0600],\n",
            "        [0.9343],\n",
            "        [0.0082],\n",
            "        [0.0935],\n",
            "        [0.0138],\n",
            "        [0.7985],\n",
            "        [0.0119],\n",
            "        [0.5649],\n",
            "        [0.2532],\n",
            "        [0.5838]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.5185,  0.6336],\n",
            "         [-0.4327, -0.3273],\n",
            "         [ 0.1112,  0.4723]],\n",
            "\n",
            "        [[-0.6005,  1.8067],\n",
            "         [ 0.8244,  2.1839],\n",
            "         [ 1.0352,  0.4566]],\n",
            "\n",
            "        [[ 0.0853,  0.4099],\n",
            "         [-1.6021,  0.8162],\n",
            "         [-0.2524,  0.5223]],\n",
            "\n",
            "        [[-0.4386, -1.5372],\n",
            "         [ 0.5441,  0.5265],\n",
            "         [ 1.0132, -0.8705]],\n",
            "\n",
            "        [[ 0.3288, -0.7082],\n",
            "         [ 1.6481, -0.8028],\n",
            "         [-1.2763, -0.0682]],\n",
            "\n",
            "        [[ 0.6233,  1.3688],\n",
            "         [-0.1759,  0.4173],\n",
            "         [-0.3586,  0.6468]],\n",
            "\n",
            "        [[-0.4021,  2.1406],\n",
            "         [ 0.7446,  0.4877],\n",
            "         [-0.3293,  0.3803]],\n",
            "\n",
            "        [[-0.8322,  1.0421],\n",
            "         [-0.4010,  1.5813],\n",
            "         [-0.3361, -0.4511]],\n",
            "\n",
            "        [[ 0.5803,  0.9855],\n",
            "         [ 0.2127,  1.7527],\n",
            "         [-1.6323, -0.0922]],\n",
            "\n",
            "        [[ 0.1440,  0.8325],\n",
            "         [-1.3355, -1.3837],\n",
            "         [-1.4907,  1.2253]],\n",
            "\n",
            "        [[-1.2580,  0.5864],\n",
            "         [-0.0068,  0.7390],\n",
            "         [ 0.8866, -0.5756]],\n",
            "\n",
            "        [[-0.4093,  0.2066],\n",
            "         [-2.0928, -0.6787],\n",
            "         [-0.1491,  1.3294]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.5232, 0.9350],\n",
            "        [1.1949, 1.2924],\n",
            "        [0.4829, 1.2600],\n",
            "        [0.4746, 0.2099],\n",
            "        [0.4421, 0.4170],\n",
            "        [0.8173, 1.0871],\n",
            "        [0.8773, 1.2020],\n",
            "        [0.5678, 1.2578],\n",
            "        [0.6289, 1.2590],\n",
            "        [0.1965, 1.1519],\n",
            "        [0.5701, 0.9175],\n",
            "        [0.1929, 1.1921]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.5232, 0.9350],\n",
            "        [1.1949, 1.2924],\n",
            "        [0.4829, 1.2600],\n",
            "        [0.4746, 0.2099],\n",
            "        [0.4421, 0.4170],\n",
            "        [0.8173, 1.0871],\n",
            "        [0.8773, 1.2020],\n",
            "        [0.5678, 1.2578],\n",
            "        [0.6289, 1.2590],\n",
            "        [0.1965, 1.1519],\n",
            "        [0.5701, 0.9175],\n",
            "        [0.1929, 1.1921]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.5168],\n",
            "        [0.4305],\n",
            "        [0.0600],\n",
            "        [0.9343],\n",
            "        [0.0082],\n",
            "        [0.0935],\n",
            "        [0.0138],\n",
            "        [0.7985],\n",
            "        [0.0119],\n",
            "        [0.5649],\n",
            "        [0.2532],\n",
            "        [0.5838]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-2.7934],\n",
            "        [ 0.3335],\n",
            "        [-3.4872],\n",
            "        [ 0.3789],\n",
            "        [-3.4381],\n",
            "        [ 0.3877],\n",
            "        [-3.9004],\n",
            "        [ 0.2126],\n",
            "        [-2.7629],\n",
            "        [ 0.1541],\n",
            "        [-2.0087],\n",
            "        [ 0.2964]]) \u001b[0m\n",
            "\u001b[35mdomain agent updated\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.1390,  1.4275],\n",
            "        [-1.3256,  0.0830],\n",
            "        [-0.0095,  0.8360],\n",
            "        [-0.4097,  0.4180],\n",
            "        [-0.5499,  0.4332],\n",
            "        [-0.7132, -0.2521]], grad_fn=<SumBackward1>)\n",
            "\u001b[95mupdates done!\u001b[0m\n",
            "\u001b[92mstarting epoch 6...\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([1, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([2, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([2, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([3, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.0081]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-1.0491, -0.4226],\n",
            "         [-2.5020, -0.5091],\n",
            "         [-0.2907,  1.2189]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.0338,  1.2681]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[-0.0338,  1.2681]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.0081]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-2.0087]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.2948, 0.0666, 0.3244, 0.3143]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([3, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([4, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([4, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([5, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([5, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([6, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.7835]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.3251,  0.2166],\n",
            "         [-0.5401,  1.7161],\n",
            "         [-0.7381,  0.5900]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.6038, 1.3270]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.6038, 1.3270]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.7835]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[0.2964]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.3997, 0.2315, 0.1122, 0.2567]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.2217,  0.1578]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[4.1194e-01, 5.8806e-01, 1.0290e-08]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 0) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([6, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([7, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([7, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([8, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([8, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([9, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.4119]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.0639, -0.6992],\n",
            "         [-0.5518, -0.0552],\n",
            "         [ 0.7768, -0.4045]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.4527, 0.4899]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.4527, 0.4899]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.4119]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-2.5346]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.1268, 0.0356, 0.7241, 0.1135]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([9, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([10, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([10, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([11, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([11, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([12, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.5881]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.1779, -0.2463],\n",
            "         [ 0.2731,  1.8345],\n",
            "         [ 0.1518, -1.3870]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.5864, 0.6435]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.5864, 0.6435]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.5881]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[0.0167]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.0006, 0.3466, 0.2458, 0.4070]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.1725, 0.4478]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.0235, 0.9682, 0.0083]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 1) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([12, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([13, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([13, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([14, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([14, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([15, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.0235]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.7035,  0.9038],\n",
            "         [-0.3982, -0.5237],\n",
            "         [-0.2652,  0.4082]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.4547, 1.0053]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.4547, 1.0053]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.0235]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-2.2987]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.1633, 0.5919, 0.1414, 0.1034]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([15, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([16, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([16, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([17, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([17, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([18, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.9682]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.0214,  1.4578],\n",
            "         [-0.4813, -0.6900],\n",
            "         [ 0.0056, -0.8828]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.4583, 0.7096]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.4583, 0.7096]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.9682]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-0.8438]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.4759, 0.4672, 0.0376, 0.0193]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.7259, -0.8428]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.6200, 0.0723, 0.3077]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 2) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([18, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([19, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([19, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([20, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([20, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([21, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.6200]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-1.4968, -0.2141],\n",
            "         [-0.5698,  2.2712],\n",
            "         [ 0.6992, -1.1325]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.4219, 1.0420]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.4219, 1.0420]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.6200]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-2.7990]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.5354, 0.0392, 0.1962, 0.2292]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([21, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([22, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([22, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([23, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([23, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([24, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.0723]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.2453,  1.9291],\n",
            "         [ 0.0052,  0.5932],\n",
            "         [-0.0879, -0.0311]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.8364, 1.0673]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.8364, 1.0673]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.0723]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-0.7970]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.2962, 0.3501, 0.1643, 0.1895]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.3348, -0.5795]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.2693, 0.6897, 0.0410]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 3) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([24, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([25, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([25, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([26, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([26, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([27, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.2693]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 2.0241, -0.6547],\n",
            "         [-0.3467, -0.1656],\n",
            "         [-0.3063,  0.6745]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.7042, 0.5517]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.7042, 0.5517]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.2693]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-3.5560]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.0100, 0.2740, 0.0408, 0.6752]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([27, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([28, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([28, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([29, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([29, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([30, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.6897]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.1274,  0.4024],\n",
            "         [ 0.3054, -0.3351],\n",
            "         [-0.2405,  0.1721]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.6173, 0.7068]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.6173, 0.7068]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.6897]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-1.0482]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.0935, 0.0511, 0.0091, 0.8463]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.4556,  1.8420]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.3352, 0.2705, 0.3942]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 4) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([30, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([31, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([31, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([32, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([32, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([33, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.3352]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.2338,  0.0163],\n",
            "         [-1.5310,  1.2419],\n",
            "         [-0.5055, -1.0698]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.3169, 0.9903]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.3169, 0.9903]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.3352]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-2.5645]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.5348, 0.4137, 0.0413, 0.0103]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([33, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([34, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([34, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([35, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([35, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([36, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.2705]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-2.1331,  0.8624],\n",
            "         [-1.1918,  1.7224],\n",
            "         [ 1.0321, -0.1572]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.4446, 1.5166]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.4446, 1.5166]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.2705]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-1.7543]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.0164, 0.0816, 0.2800, 0.6220]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.4206, 0.7976]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.3361, 0.6360, 0.0279]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 5) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[95mupadating all agents\u001b[0m\n",
            "\u001b[35masset agent updated\u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.0081],\n",
            "        [0.7835],\n",
            "        [0.4119],\n",
            "        [0.5881],\n",
            "        [0.0235],\n",
            "        [0.9682],\n",
            "        [0.6200],\n",
            "        [0.0723],\n",
            "        [0.2693],\n",
            "        [0.6897],\n",
            "        [0.3352],\n",
            "        [0.2705]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-1.0491, -0.4226],\n",
            "         [-2.5020, -0.5091],\n",
            "         [-0.2907,  1.2189]],\n",
            "\n",
            "        [[-0.3251,  0.2166],\n",
            "         [-0.5401,  1.7161],\n",
            "         [-0.7381,  0.5900]],\n",
            "\n",
            "        [[-0.0639, -0.6992],\n",
            "         [-0.5518, -0.0552],\n",
            "         [ 0.7768, -0.4045]],\n",
            "\n",
            "        [[-0.1779, -0.2463],\n",
            "         [ 0.2731,  1.8345],\n",
            "         [ 0.1518, -1.3870]],\n",
            "\n",
            "        [[-0.7035,  0.9038],\n",
            "         [-0.3982, -0.5237],\n",
            "         [-0.2652,  0.4082]],\n",
            "\n",
            "        [[-0.0214,  1.4578],\n",
            "         [-0.4813, -0.6900],\n",
            "         [ 0.0056, -0.8828]],\n",
            "\n",
            "        [[-1.4968, -0.2141],\n",
            "         [-0.5698,  2.2712],\n",
            "         [ 0.6992, -1.1325]],\n",
            "\n",
            "        [[ 0.2453,  1.9291],\n",
            "         [ 0.0052,  0.5932],\n",
            "         [-0.0879, -0.0311]],\n",
            "\n",
            "        [[ 2.0241, -0.6547],\n",
            "         [-0.3467, -0.1656],\n",
            "         [-0.3063,  0.6745]],\n",
            "\n",
            "        [[ 0.1274,  0.4024],\n",
            "         [ 0.3054, -0.3351],\n",
            "         [-0.2405,  0.1721]],\n",
            "\n",
            "        [[ 0.2338,  0.0163],\n",
            "         [-1.5310,  1.2419],\n",
            "         [-0.5055, -1.0698]],\n",
            "\n",
            "        [[-2.1331,  0.8624],\n",
            "         [-1.1918,  1.7224],\n",
            "         [ 1.0321, -0.1572]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.0338,  1.2681],\n",
            "        [ 0.6038,  1.3270],\n",
            "        [ 0.4527,  0.4899],\n",
            "        [ 0.5864,  0.6435],\n",
            "        [ 0.4547,  1.0053],\n",
            "        [ 0.4583,  0.7096],\n",
            "        [ 0.4219,  1.0420],\n",
            "        [ 0.8364,  1.0673],\n",
            "        [ 0.7042,  0.5517],\n",
            "        [ 0.6173,  0.7068],\n",
            "        [ 0.3169,  0.9903],\n",
            "        [ 0.4446,  1.5166]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[-0.0338,  1.2681],\n",
            "        [ 0.6038,  1.3270],\n",
            "        [ 0.4527,  0.4899],\n",
            "        [ 0.5864,  0.6435],\n",
            "        [ 0.4547,  1.0053],\n",
            "        [ 0.4583,  0.7096],\n",
            "        [ 0.4219,  1.0420],\n",
            "        [ 0.8364,  1.0673],\n",
            "        [ 0.7042,  0.5517],\n",
            "        [ 0.6173,  0.7068],\n",
            "        [ 0.3169,  0.9903],\n",
            "        [ 0.4446,  1.5166]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.0081],\n",
            "        [0.7835],\n",
            "        [0.4119],\n",
            "        [0.5881],\n",
            "        [0.0235],\n",
            "        [0.9682],\n",
            "        [0.6200],\n",
            "        [0.0723],\n",
            "        [0.2693],\n",
            "        [0.6897],\n",
            "        [0.3352],\n",
            "        [0.2705]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-2.5346],\n",
            "        [ 0.0167],\n",
            "        [-2.2987],\n",
            "        [-0.8438],\n",
            "        [-2.7990],\n",
            "        [-0.7970],\n",
            "        [-3.5560],\n",
            "        [-1.0482],\n",
            "        [-2.5645],\n",
            "        [-1.7543],\n",
            "        [-1.8315],\n",
            "        [-2.4236]]) \u001b[0m\n",
            "\u001b[35mdomain agent updated\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.2217,  0.1578],\n",
            "        [ 0.1725,  0.4478],\n",
            "        [-0.7259, -0.8428],\n",
            "        [-0.3348, -0.5795],\n",
            "        [-0.4556,  1.8420],\n",
            "        [ 0.4206,  0.7976]], grad_fn=<SumBackward1>)\n",
            "\u001b[95mupdates done!\u001b[0m\n",
            "\u001b[92mstarting epoch 7...\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([1, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([2, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([2, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([3, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.3361]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-1.7032,  0.0985],\n",
            "         [-1.2790, -0.9391],\n",
            "         [-0.6191, -0.9755]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.1373,  0.8876]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[-0.1373,  0.8876]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.3361]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-1.8315]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.1225, 0.0233, 0.0191, 0.8350]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([3, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([4, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([4, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([5, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([5, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([6, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.6360]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.3391,  0.7839],\n",
            "         [ 0.5512, -0.7748],\n",
            "         [ 1.7011,  0.1284]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.8193, 0.4861]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.8193, 0.4861]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.6360]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-2.4236]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.4265, 0.1668, 0.0729, 0.3338]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-1.2342,  0.3271]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.1810, 0.5219, 0.2972]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 0) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([6, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([7, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([7, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([8, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([8, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([9, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.1810]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-1.3434, -0.7237],\n",
            "         [-2.0554,  1.7420],\n",
            "         [-1.4425, -0.1309]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.0231,  1.4914]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[-0.0231,  1.4914]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.1810]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-2.4643]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.0479, 0.6873, 0.1539, 0.1109]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([9, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([10, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([10, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([11, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([11, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([12, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.5219]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.4258,  0.4761],\n",
            "         [ 0.0428, -0.1353],\n",
            "         [-1.4245,  0.0506]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.3332, 1.0220]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.3332, 1.0220]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.5219]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-2.6322]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.3627, 0.4056, 0.1262, 0.1055]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[3.1418, 3.7067]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.1979, 0.7118, 0.0903]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 1) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([12, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([13, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([13, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([14, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([14, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([15, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.1979]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 1.7906,  0.8704],\n",
            "         [-0.7935,  1.1424],\n",
            "         [ 0.9883,  0.4293]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[1.0531, 0.8993]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[1.0531, 0.8993]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.1979]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-2.5134]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.0212, 0.1199, 0.3225, 0.5364]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([15, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([16, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([16, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([17, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([17, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([18, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.7118]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 2.0466, -0.0572],\n",
            "         [ 0.8941, -1.0790],\n",
            "         [ 0.0926,  1.2087]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.9748, 0.3135]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.9748, 0.3135]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.7118]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-2.6286]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.3958, 0.1606, 0.0079, 0.4357]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.7498, 1.7939]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.0358, 0.9534, 0.0108]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 2) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([18, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([19, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([19, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([20, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([20, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([21, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.0358]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 1.1937, -1.4330],\n",
            "         [ 0.7369, -0.1039],\n",
            "         [ 2.6020, -0.6386]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[ 0.9385, -0.2681]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[ 0.9385, -0.2681]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.0358]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-3.0007]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.1891, 0.7051, 0.0584, 0.0474]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([21, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([22, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([22, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([23, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([23, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([24, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.9534]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-1.3249, -0.9408],\n",
            "         [-1.8742,  0.9519],\n",
            "         [ 0.9041,  0.4376]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.2046, 1.1307]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.2046, 1.1307]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.9534]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-2.5846]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.4204, 0.1474, 0.1652, 0.2671]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.6096,  0.8754]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.0444, 0.5969, 0.3587]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 3) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([24, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([25, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([25, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([26, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([26, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([27, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.0444]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 1.0905, -3.0315],\n",
            "         [-0.5783,  0.2003],\n",
            "         [-1.3014,  0.5635]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.2157, 0.4688]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.2157, 0.4688]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.0444]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-3.3841]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.3715, 0.3862, 0.1364, 0.1059]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([27, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([28, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([28, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([29, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([29, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([30, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.5969]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-1.4500,  1.1096],\n",
            "         [-0.7183,  0.6964],\n",
            "         [-1.0871, -1.4048]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.1293, 1.1770]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.1293, 1.1770]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.5969]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-2.1823]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.1182, 0.1680, 0.5823, 0.1316]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.9093, 1.6367]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.2365, 0.7514, 0.0121]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 4) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([30, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([31, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([31, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([32, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([32, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([33, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.2365]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-1.1789,  0.0638],\n",
            "         [-0.3787,  1.8168],\n",
            "         [-1.1517, -1.6334]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.1453, 1.0392]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.1453, 1.0392]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.2365]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-3.0362]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.4520, 0.0330, 0.1838, 0.3312]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([33, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([34, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([34, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([35, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([35, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([36, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.7514]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.6696,  0.6886],\n",
            "         [-0.8484,  0.7132],\n",
            "         [-0.2263, -0.3239]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.5991, 0.9405]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.5991, 0.9405]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.7514]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-2.4373]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.3203, 0.5302, 0.0282, 0.1214]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.1149, 1.6621]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.3693, 0.6000, 0.0307]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 5) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[95mupadating all agents\u001b[0m\n",
            "\u001b[35masset agent updated\u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.3361],\n",
            "        [0.6360],\n",
            "        [0.1810],\n",
            "        [0.5219],\n",
            "        [0.1979],\n",
            "        [0.7118],\n",
            "        [0.0358],\n",
            "        [0.9534],\n",
            "        [0.0444],\n",
            "        [0.5969],\n",
            "        [0.2365],\n",
            "        [0.7514]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-1.7032,  0.0985],\n",
            "         [-1.2790, -0.9391],\n",
            "         [-0.6191, -0.9755]],\n",
            "\n",
            "        [[-0.3391,  0.7839],\n",
            "         [ 0.5512, -0.7748],\n",
            "         [ 1.7011,  0.1284]],\n",
            "\n",
            "        [[-1.3434, -0.7237],\n",
            "         [-2.0554,  1.7420],\n",
            "         [-1.4425, -0.1309]],\n",
            "\n",
            "        [[-0.4258,  0.4761],\n",
            "         [ 0.0428, -0.1353],\n",
            "         [-1.4245,  0.0506]],\n",
            "\n",
            "        [[ 1.7906,  0.8704],\n",
            "         [-0.7935,  1.1424],\n",
            "         [ 0.9883,  0.4293]],\n",
            "\n",
            "        [[ 2.0466, -0.0572],\n",
            "         [ 0.8941, -1.0790],\n",
            "         [ 0.0926,  1.2087]],\n",
            "\n",
            "        [[ 1.1937, -1.4330],\n",
            "         [ 0.7369, -0.1039],\n",
            "         [ 2.6020, -0.6386]],\n",
            "\n",
            "        [[-1.3249, -0.9408],\n",
            "         [-1.8742,  0.9519],\n",
            "         [ 0.9041,  0.4376]],\n",
            "\n",
            "        [[ 1.0905, -3.0315],\n",
            "         [-0.5783,  0.2003],\n",
            "         [-1.3014,  0.5635]],\n",
            "\n",
            "        [[-1.4500,  1.1096],\n",
            "         [-0.7183,  0.6964],\n",
            "         [-1.0871, -1.4048]],\n",
            "\n",
            "        [[-1.1789,  0.0638],\n",
            "         [-0.3787,  1.8168],\n",
            "         [-1.1517, -1.6334]],\n",
            "\n",
            "        [[ 0.6696,  0.6886],\n",
            "         [-0.8484,  0.7132],\n",
            "         [-0.2263, -0.3239]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.1373,  0.8876],\n",
            "        [ 0.8193,  0.4861],\n",
            "        [-0.0231,  1.4914],\n",
            "        [ 0.3332,  1.0220],\n",
            "        [ 1.0531,  0.8993],\n",
            "        [ 0.9748,  0.3135],\n",
            "        [ 0.9385, -0.2681],\n",
            "        [ 0.2046,  1.1307],\n",
            "        [ 0.2157,  0.4688],\n",
            "        [ 0.1293,  1.1770],\n",
            "        [ 0.1453,  1.0392],\n",
            "        [ 0.5991,  0.9405]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[-0.1373,  0.8876],\n",
            "        [ 0.8193,  0.4861],\n",
            "        [-0.0231,  1.4914],\n",
            "        [ 0.3332,  1.0220],\n",
            "        [ 1.0531,  0.8993],\n",
            "        [ 0.9748,  0.3135],\n",
            "        [ 0.9385, -0.2681],\n",
            "        [ 0.2046,  1.1307],\n",
            "        [ 0.2157,  0.4688],\n",
            "        [ 0.1293,  1.1770],\n",
            "        [ 0.1453,  1.0392],\n",
            "        [ 0.5991,  0.9405]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.3361],\n",
            "        [0.6360],\n",
            "        [0.1810],\n",
            "        [0.5219],\n",
            "        [0.1979],\n",
            "        [0.7118],\n",
            "        [0.0358],\n",
            "        [0.9534],\n",
            "        [0.0444],\n",
            "        [0.5969],\n",
            "        [0.2365],\n",
            "        [0.7514]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-2.4643],\n",
            "        [-2.6322],\n",
            "        [-2.5134],\n",
            "        [-2.6286],\n",
            "        [-3.0007],\n",
            "        [-2.5846],\n",
            "        [-3.3841],\n",
            "        [-2.1823],\n",
            "        [-3.0362],\n",
            "        [-2.4373],\n",
            "        [-3.1717],\n",
            "        [-2.3372]]) \u001b[0m\n",
            "\u001b[35mdomain agent updated\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-1.2342,  0.3271],\n",
            "        [ 3.1418,  3.7067],\n",
            "        [ 0.7498,  1.7939],\n",
            "        [-0.6096,  0.8754],\n",
            "        [ 0.9093,  1.6367],\n",
            "        [ 0.1149,  1.6621]], grad_fn=<SumBackward1>)\n",
            "\u001b[95mupdates done!\u001b[0m\n",
            "\u001b[92mstarting epoch 8...\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([1, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([2, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([2, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([3, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.3693]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.8089,  1.0388],\n",
            "         [-0.6931, -0.2279],\n",
            "         [-0.1547, -0.3118]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.3831, 1.0000]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.3831, 1.0000]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.3693]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-3.1717]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.3681, 0.3053, 0.2861, 0.0405]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([3, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([4, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([4, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([5, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([5, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([6, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.6000]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.5253, -0.7911],\n",
            "         [ 1.0254,  0.0303],\n",
            "         [-1.5438,  0.1353]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.4426, 0.6557]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.4426, 0.6557]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.6000]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-2.3372]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[7.3500e-01, 1.7230e-01, 9.2701e-02, 3.3946e-07]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.7145,  2.0154]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.0385, 0.5751, 0.3865]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 0) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([6, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([7, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([7, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([8, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([8, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([9, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.0385]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.1562, -0.1375],\n",
            "         [-0.2044,  0.9602],\n",
            "         [-0.6992, -0.7904]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.4417, 0.7855]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.4417, 0.7855]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.0385]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-3.1815]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.6242, 0.1525, 0.0309, 0.1924]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([9, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([10, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([10, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([11, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([11, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([12, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.5751]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.8825,  0.9429],\n",
            "         [-0.9586,  1.1550],\n",
            "         [-0.8041, -1.3880]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.2512, 1.1387]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.2512, 1.1387]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.5751]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-2.8963]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.1829, 0.0062, 0.0014, 0.8095]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.8780, 2.2077]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.1325, 0.3469, 0.5206]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 1) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([12, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([13, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([13, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([14, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([14, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([15, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.1325]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 1.9360, -1.8469],\n",
            "         [-0.5282, -0.9939],\n",
            "         [-0.4035,  0.5455]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.4302, 0.2403]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.4302, 0.2403]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.1325]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-3.1424]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.5914, 0.0384, 0.3454, 0.0247]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([15, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([16, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([16, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([17, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([17, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([18, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.3469]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.1141,  1.1831],\n",
            "         [ 0.6653,  1.2312],\n",
            "         [-0.0301,  0.5216]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.9740, 1.0819]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.9740, 1.0819]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.3469]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-3.8155]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.0373, 0.1070, 0.6744, 0.1813]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.5665, 0.2553]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.0050, 0.9236, 0.0715]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 2) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([18, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([19, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([19, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([20, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([20, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([21, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.0050]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.7697, -1.5353],\n",
            "         [-1.1027,  0.6354],\n",
            "         [ 1.3256, -1.6286]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.4273, 0.2043]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.4273, 0.2043]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.0050]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-3.1220]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.0336, 0.1671, 0.3657, 0.4336]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([21, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([22, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([22, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([23, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([23, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([24, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.9236]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-1.1804, -1.0434],\n",
            "         [-0.2990, -0.4995],\n",
            "         [ 1.1860,  0.3395]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.3078, 0.5445]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.3078, 0.5445]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.9236]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-3.5375]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.1279, 0.7525, 0.0016, 0.1180]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[1.6344, 0.4768]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.2574, 0.2733, 0.4693]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 3) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([24, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([25, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([25, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([26, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([26, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([27, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.2574]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-1.1782, -0.4001],\n",
            "         [-0.3443, -0.6326],\n",
            "         [ 1.8878, -1.3024]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.3097, 0.3480]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.3097, 0.3480]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.2574]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-3.2999]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.3087, 0.2166, 0.0541, 0.4206]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([27, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([28, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([28, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([29, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([29, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([30, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.2733]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 1.1519, -0.8861],\n",
            "         [ 0.2841, -1.1356],\n",
            "         [ 0.6306,  0.0612]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.6359, 0.0772]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.6359, 0.0772]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.2733]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-3.6346]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.9565, 0.0371, 0.0040, 0.0024]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-2.0813, -0.1790]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.0017, 0.9878, 0.0105]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 4) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([30, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([31, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([31, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([32, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([32, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([33, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.0017]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-1.7915, -1.4245],\n",
            "         [-1.4053, -0.2733],\n",
            "         [-0.2388,  0.2320]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.1292,  0.9044]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[-0.1292,  0.9044]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.0017]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-3.4784]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.0448, 0.5751, 0.1381, 0.2420]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([33, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([34, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([34, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([35, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([35, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([36, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.9878]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.0795,  0.6374],\n",
            "         [-0.6469,  1.3490],\n",
            "         [-2.5298, -0.9187]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.1026, 1.2940]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.1026, 1.2940]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.9878]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-3.0037]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.0349, 0.8867, 0.0325, 0.0458]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.0071,  0.7570]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[1.0485e-01, 8.9455e-01, 6.0627e-04]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 5) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[95mupadating all agents\u001b[0m\n",
            "\u001b[35masset agent updated\u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.3693],\n",
            "        [0.6000],\n",
            "        [0.0385],\n",
            "        [0.5751],\n",
            "        [0.1325],\n",
            "        [0.3469],\n",
            "        [0.0050],\n",
            "        [0.9236],\n",
            "        [0.2574],\n",
            "        [0.2733],\n",
            "        [0.0017],\n",
            "        [0.9878]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.8089,  1.0388],\n",
            "         [-0.6931, -0.2279],\n",
            "         [-0.1547, -0.3118]],\n",
            "\n",
            "        [[ 0.5253, -0.7911],\n",
            "         [ 1.0254,  0.0303],\n",
            "         [-1.5438,  0.1353]],\n",
            "\n",
            "        [[ 0.1562, -0.1375],\n",
            "         [-0.2044,  0.9602],\n",
            "         [-0.6992, -0.7904]],\n",
            "\n",
            "        [[-0.8825,  0.9429],\n",
            "         [-0.9586,  1.1550],\n",
            "         [-0.8041, -1.3880]],\n",
            "\n",
            "        [[ 1.9360, -1.8469],\n",
            "         [-0.5282, -0.9939],\n",
            "         [-0.4035,  0.5455]],\n",
            "\n",
            "        [[ 0.1141,  1.1831],\n",
            "         [ 0.6653,  1.2312],\n",
            "         [-0.0301,  0.5216]],\n",
            "\n",
            "        [[ 0.7697, -1.5353],\n",
            "         [-1.1027,  0.6354],\n",
            "         [ 1.3256, -1.6286]],\n",
            "\n",
            "        [[-1.1804, -1.0434],\n",
            "         [-0.2990, -0.4995],\n",
            "         [ 1.1860,  0.3395]],\n",
            "\n",
            "        [[-1.1782, -0.4001],\n",
            "         [-0.3443, -0.6326],\n",
            "         [ 1.8878, -1.3024]],\n",
            "\n",
            "        [[ 1.1519, -0.8861],\n",
            "         [ 0.2841, -1.1356],\n",
            "         [ 0.6306,  0.0612]],\n",
            "\n",
            "        [[-1.7915, -1.4245],\n",
            "         [-1.4053, -0.2733],\n",
            "         [-0.2388,  0.2320]],\n",
            "\n",
            "        [[ 0.0795,  0.6374],\n",
            "         [-0.6469,  1.3490],\n",
            "         [-2.5298, -0.9187]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[ 0.3831,  1.0000],\n",
            "        [ 0.4426,  0.6557],\n",
            "        [ 0.4417,  0.7855],\n",
            "        [ 0.2512,  1.1387],\n",
            "        [ 0.4302,  0.2403],\n",
            "        [ 0.9740,  1.0819],\n",
            "        [ 0.4273,  0.2043],\n",
            "        [ 0.3078,  0.5445],\n",
            "        [ 0.3097,  0.3480],\n",
            "        [ 0.6359,  0.0772],\n",
            "        [-0.1292,  0.9044],\n",
            "        [ 0.1026,  1.2940]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[ 0.3831,  1.0000],\n",
            "        [ 0.4426,  0.6557],\n",
            "        [ 0.4417,  0.7855],\n",
            "        [ 0.2512,  1.1387],\n",
            "        [ 0.4302,  0.2403],\n",
            "        [ 0.9740,  1.0819],\n",
            "        [ 0.4273,  0.2043],\n",
            "        [ 0.3078,  0.5445],\n",
            "        [ 0.3097,  0.3480],\n",
            "        [ 0.6359,  0.0772],\n",
            "        [-0.1292,  0.9044],\n",
            "        [ 0.1026,  1.2940]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.3693],\n",
            "        [0.6000],\n",
            "        [0.0385],\n",
            "        [0.5751],\n",
            "        [0.1325],\n",
            "        [0.3469],\n",
            "        [0.0050],\n",
            "        [0.9236],\n",
            "        [0.2574],\n",
            "        [0.2733],\n",
            "        [0.0017],\n",
            "        [0.9878]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-3.1815],\n",
            "        [-2.8963],\n",
            "        [-3.1424],\n",
            "        [-3.8155],\n",
            "        [-3.1220],\n",
            "        [-3.5375],\n",
            "        [-3.2999],\n",
            "        [-3.6346],\n",
            "        [-3.4784],\n",
            "        [-3.0037],\n",
            "        [-3.7555],\n",
            "        [-2.7124]]) \u001b[0m\n",
            "\u001b[35mdomain agent updated\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.7145,  2.0154],\n",
            "        [ 0.8780,  2.2077],\n",
            "        [ 0.5665,  0.2553],\n",
            "        [ 1.6344,  0.4768],\n",
            "        [-2.0813, -0.1790],\n",
            "        [-0.0071,  0.7570]], grad_fn=<SumBackward1>)\n",
            "\u001b[95mupdates done!\u001b[0m\n",
            "\u001b[92mstarting epoch 9...\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([1, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([2, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([2, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([3, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.1048]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.0195,  1.5738],\n",
            "         [-0.9953,  0.0023],\n",
            "         [ 0.7571, -0.6563]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.5941, 0.8917]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.5941, 0.8917]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.1048]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-3.7555]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[7.3502e-02, 6.2806e-01, 4.3087e-04, 2.9801e-01]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([3, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([4, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([4, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([5, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([5, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([6, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.8945]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.9671, -0.6192],\n",
            "         [-1.8983,  0.0841],\n",
            "         [ 1.3587,  1.2420]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.2787, 1.0604]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.2787, 1.0604]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.8945]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-2.7124]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.3192, 0.2703, 0.3315, 0.0789]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.6684, 1.1450]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.0164, 0.7449, 0.2387]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 0) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([6, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([7, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([7, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([8, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([8, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([9, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.0164]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.5583, -0.5364],\n",
            "         [-0.8428,  0.6019],\n",
            "         [-1.7724, -1.2361]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.0462,  0.9142]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[-0.0462,  0.9142]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.0164]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-4.0055]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.3759, 0.1309, 0.0070, 0.4862]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([9, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([10, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([10, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([11, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([11, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([12, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.7449]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 1.1084,  0.8671],\n",
            "         [ 1.3863, -1.8982],\n",
            "         [ 1.6366,  1.1046]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[1.1211, 0.0915]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[1.1211, 0.0915]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.7449]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-2.9428]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.2568, 0.1260, 0.3641, 0.2532]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.3361, 0.3040]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.2464, 0.6401, 0.1135]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 1) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([12, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([13, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([13, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([14, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([14, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([15, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.2464]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.4249, -0.0603],\n",
            "         [ 0.4848,  0.7456],\n",
            "         [-0.1187,  0.5033]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.7992, 0.7844]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.7992, 0.7844]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.2464]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-3.3804]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.5725, 0.0595, 0.3631, 0.0049]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([15, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([16, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([16, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([17, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([17, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([18, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.6401]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.4963, -1.0627],\n",
            "         [-2.8960, -0.3869],\n",
            "         [ 1.7109, -1.8315]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.1471,  0.5897]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[-0.1471,  0.5897]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.6401]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-2.8799]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.8909, 0.0359, 0.0209, 0.0523]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.3839,  0.5765]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.0207, 0.8537, 0.1256]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 2) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([18, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([19, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([19, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([20, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([20, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([21, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.0207]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.4575, -0.3051],\n",
            "         [ 0.1111, -0.2476],\n",
            "         [-1.1123,  0.2486]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.4419, 0.7433]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.4419, 0.7433]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.0207]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-2.8330]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.0617, 0.7634, 0.0634, 0.1116]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([21, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([22, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([22, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([23, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([23, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([24, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.8537]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-0.4863, -0.0955],\n",
            "         [-1.4558,  0.9646],\n",
            "         [ 0.6005, -1.1708]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.3404, 0.8711]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.3404, 0.8711]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.8537]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-2.3276]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.0518, 0.2039, 0.2888, 0.4555]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[1.8983, 2.2287]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[1.1513e-04, 9.7246e-01, 2.7421e-02]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 3) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([24, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([25, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([25, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([26, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([26, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([27, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.0001]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.8525,  0.6554],\n",
            "         [-0.0761, -0.5554],\n",
            "         [ 1.6640, -0.0960]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.8685, 0.3715]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.8685, 0.3715]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.0001]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-2.6824]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.1720, 0.5043, 0.1433, 0.1804]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([27, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([28, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([28, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([29, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([29, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([30, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.9725]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-1.6925,  1.1373],\n",
            "         [ 2.0056,  0.6523],\n",
            "         [ 1.2794,  1.3975]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.9938, 1.1560]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.9938, 1.1560]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.9725]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-2.2035]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.5233, 0.1597, 0.2812, 0.0357]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.1091,  0.4704]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[1.3101e-01, 8.6863e-01, 3.5698e-04]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 4) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([30, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([31, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([31, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([32, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([32, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([33, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.1310]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[ 0.7870,  0.0266],\n",
            "         [-1.2719, -1.4095],\n",
            "         [ 0.1681, -1.1620]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[0.1750, 0.3153]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[0.1750, 0.3153]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.1310]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-2.8063]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.4534, 0.2181, 0.0713, 0.2572]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([33, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([34, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([34, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([35, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer before:  torch.Size([35, 60, 17]) \u001b[0m\n",
            "\u001b[91m asset buffer after:  torch.Size([36, 60, 17]) \u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[0.8686]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[0.0817, 1.0439],\n",
            "         [0.2144, 0.1757],\n",
            "         [0.8663, 1.6623]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[1.0155, 1.0076]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[1.0155, 1.0076]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[0.8686]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-2.6018]]) \u001b[0m\n",
            "\u001b[92m all allocations (domain output) tensor([[0.3150, 0.0509, 0.4109, 0.2231]]) \u001b[0m\n",
            "\u001b[35mdomain done\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[-0.1327,  0.4059]], grad_fn=<SumBackward1>)\n",
            "\u001b[92m all allocations (master output) tensor([[0.0776, 0.5220, 0.4004]]) \u001b[0m\n",
            "\u001b[97mone asset-domain-master cycle (window: 5) done -----------------------------------------------------\u001b[0m\n",
            "\u001b[95mupadating all agents\u001b[0m\n",
            "\u001b[35masset agent updated\u001b[0m\n",
            "\u001b[35mmaster signal:  tensor([[1.0485e-01],\n",
            "        [8.9455e-01],\n",
            "        [1.6419e-02],\n",
            "        [7.4488e-01],\n",
            "        [2.4640e-01],\n",
            "        [6.4006e-01],\n",
            "        [2.0651e-02],\n",
            "        [8.5372e-01],\n",
            "        [1.1513e-04],\n",
            "        [9.7246e-01],\n",
            "        [1.3101e-01],\n",
            "        [8.6863e-01]]) \u001b[0m\n",
            "\u001b[35mh_assets:  tensor([[[-1.9536e-02,  1.5738e+00],\n",
            "         [-9.9530e-01,  2.3105e-03],\n",
            "         [ 7.5708e-01, -6.5630e-01]],\n",
            "\n",
            "        [[-9.6714e-01, -6.1919e-01],\n",
            "         [-1.8983e+00,  8.4119e-02],\n",
            "         [ 1.3587e+00,  1.2420e+00]],\n",
            "\n",
            "        [[-5.5832e-01, -5.3643e-01],\n",
            "         [-8.4279e-01,  6.0190e-01],\n",
            "         [-1.7724e+00, -1.2361e+00]],\n",
            "\n",
            "        [[ 1.1084e+00,  8.6710e-01],\n",
            "         [ 1.3863e+00, -1.8982e+00],\n",
            "         [ 1.6366e+00,  1.1046e+00]],\n",
            "\n",
            "        [[ 4.2485e-01, -6.0256e-02],\n",
            "         [ 4.8482e-01,  7.4562e-01],\n",
            "         [-1.1871e-01,  5.0335e-01]],\n",
            "\n",
            "        [[-4.9633e-01, -1.0627e+00],\n",
            "         [-2.8960e+00, -3.8690e-01],\n",
            "         [ 1.7109e+00, -1.8315e+00]],\n",
            "\n",
            "        [[ 4.5754e-01, -3.0510e-01],\n",
            "         [ 1.1108e-01, -2.4757e-01],\n",
            "         [-1.1123e+00,  2.4864e-01]],\n",
            "\n",
            "        [[-4.8632e-01, -9.5481e-02],\n",
            "         [-1.4558e+00,  9.6458e-01],\n",
            "         [ 6.0046e-01, -1.1708e+00]],\n",
            "\n",
            "        [[ 8.5247e-01,  6.5540e-01],\n",
            "         [-7.6128e-02, -5.5537e-01],\n",
            "         [ 1.6640e+00, -9.5974e-02]],\n",
            "\n",
            "        [[-1.6925e+00,  1.1373e+00],\n",
            "         [ 2.0056e+00,  6.5226e-01],\n",
            "         [ 1.2794e+00,  1.3975e+00]],\n",
            "\n",
            "        [[ 7.8700e-01,  2.6649e-02],\n",
            "         [-1.2719e+00, -1.4095e+00],\n",
            "         [ 1.6815e-01, -1.1620e+00]],\n",
            "\n",
            "        [[ 8.1699e-02,  1.0439e+00],\n",
            "         [ 2.1445e-01,  1.7566e-01],\n",
            "         [ 8.6628e-01,  1.6623e+00]]]) \u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[ 0.5941,  0.8917],\n",
            "        [ 0.2787,  1.0604],\n",
            "        [-0.0462,  0.9142],\n",
            "        [ 1.1211,  0.0915],\n",
            "        [ 0.7992,  0.7844],\n",
            "        [-0.1471,  0.5897],\n",
            "        [ 0.4419,  0.7433],\n",
            "        [ 0.3404,  0.8711],\n",
            "        [ 0.8685,  0.3715],\n",
            "        [ 0.9938,  1.1560],\n",
            "        [ 0.1750,  0.3153],\n",
            "        [ 1.0155,  1.0076]], grad_fn=<SumBackward1>)\n",
            "\u001b[93mattention pool done (domain agent)\u001b[0m\n",
            "\u001b[94m h_sector tensor([[ 0.5941,  0.8917],\n",
            "        [ 0.2787,  1.0604],\n",
            "        [-0.0462,  0.9142],\n",
            "        [ 1.1211,  0.0915],\n",
            "        [ 0.7992,  0.7844],\n",
            "        [-0.1471,  0.5897],\n",
            "        [ 0.4419,  0.7433],\n",
            "        [ 0.3404,  0.8711],\n",
            "        [ 0.8685,  0.3715],\n",
            "        [ 0.9938,  1.1560],\n",
            "        [ 0.1750,  0.3153],\n",
            "        [ 1.0155,  1.0076]], grad_fn=<SumBackward1>) \u001b[0m\n",
            "\u001b[94m master_signal tensor([[1.0485e-01],\n",
            "        [8.9455e-01],\n",
            "        [1.6419e-02],\n",
            "        [7.4488e-01],\n",
            "        [2.4640e-01],\n",
            "        [6.4006e-01],\n",
            "        [2.0651e-02],\n",
            "        [8.5372e-01],\n",
            "        [1.1513e-04],\n",
            "        [9.7246e-01],\n",
            "        [1.3101e-01],\n",
            "        [8.6863e-01]]) \u001b[0m\n",
            "\u001b[94m mem tensor([[-4.0055],\n",
            "        [-2.9428],\n",
            "        [-3.3804],\n",
            "        [-2.8799],\n",
            "        [-2.8330],\n",
            "        [-2.3276],\n",
            "        [-2.6824],\n",
            "        [-2.2035],\n",
            "        [-2.8063],\n",
            "        [-2.6018],\n",
            "        [-2.9320],\n",
            "        [-3.0995]]) \u001b[0m\n",
            "\u001b[35mdomain agent updated\u001b[0m\n",
            "\u001b[92mh_out from attention pool is:  tensor([[ 0.6684,  1.1450],\n",
            "        [ 0.3361,  0.3040],\n",
            "        [-0.3839,  0.5765],\n",
            "        [ 1.8983,  2.2287],\n",
            "        [-0.1091,  0.4704],\n",
            "        [-0.1327,  0.4059]], grad_fn=<SumBackward1>)\n",
            "\u001b[95mupdates done!\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HRLFNnn4MxI-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}